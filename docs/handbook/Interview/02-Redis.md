# Redis

## Redis基础

### 1.Redis是什么？简述它的优缺点✔

- redis是一个key-value 类型的内存数据库，很像Memcached，整个数据库加载在内存当中操作，定期通过异步操作把数据库中的数据flush到硬盘上进行保存。

- 优点
  - 读写性能极高，110000次/s，81000次/s

  - 支持数据持久化（AOF、RDB）

  - 支持事务

    Redis 提供了简单的事务支持，通过 MULTI 和 EXEC 命令可以对一批命令进行原子性的执行。这意味着在一个事务中的多个命令要么全部执行成功，要么全部执行失败。这样可以确保在并发环境下保持数据的一致性。

  - 数据结构丰富，string、list、hash、set、sortset

  - 支持主从复制

  - 发布订阅功能

    Redis 支持发布与订阅模式，可以轻松实现消息队列系统。发布者可以将消息发送到特定的频道，而订阅者则可以订阅感兴趣的频道并接收消息。这种发布订阅模式使得 Redis 可以用于构建实时消息系统、实时推送系统等。

  - 分布式锁支持

    Redis 中的分布式锁机制能够帮助解决并发场景下的资源竞争问题。利用 Redis 提供的原子性操作和 SETNX（SET if Not eXists）命令，可以实现简单而可靠的分布式锁，从而保证了数据访问的互斥性。

- 缺点

  - 不适用于海量数据的高性能读写
  - 主从架构，降低了系统的可用性（主机宕机造成的数据不一致问题）

### 2.Redis为什么这么快✔

1. 内存存储，没有磁盘IO上的开销。
2. 单线程实现，Redis使用单个线程处理请求，避免了多个线程之间线程切换和锁资源争用的开销。
3. 使用多路I/O复用模型，**非阻塞IO**，主要体现在网络IO上，在进行IO操作时，应用程序不会被阻塞，可以继续执行其他操作，这个过程是异步的。
4. 优化的数据结构
5. 使用底层模型不同，Redis直接自己构建了 VM (虚拟内存)机制 

> - 阻塞IO
>
> 顾名思义，阻塞IO就是两个阶段都必须阻塞等待：
>
> 阶段一：
>
> ①用户进程尝试读取数据（比如网卡数据）
>
> ②此时数据尚未到达，内核需要等待数据
>
> ③此时用户进程也处于阻塞状态
>
> 阶段二：
>
> ①数据到达并拷贝到内核缓冲区，代表已就绪
>
> ②将内核数据拷贝到用户缓冲区
>
> ③拷贝过程中，用户进程依然阻塞等待
>
> ④拷贝完成，用户进程解除阻塞，处理数据
>
> ![image-20230607100158745](https://gitee.com/tjlxy/img/raw/master/image-20230607100158745.png)
>
> 可以看到，阻塞IO模型中，用户进程在两个阶段都是阻塞状态。
>
> - 非阻塞IO
>
> 顾名思义，非阻塞IO的recvfrom操作会立即返回结果而不是阻塞用户进程。
>
> 阶段一：
>
> ①用户进程尝试读取数据（比如网卡数据）
>
> ②此时数据尚未到达，内核需要等待数据
>
> ③返回异常给用户进程
>
> ④用户进程拿到error后，再次尝试读取
>
> ⑤循环往复，直到数据就绪
>
> 阶段二：
>
> ①将内核数据拷贝到用户缓冲区
>
> ②拷贝过程中，用户进程依然阻塞等待
>
> ③拷贝完成，用户进程解除阻塞，处理数据
>
> ![image-20230607100210540](https://gitee.com/tjlxy/img/raw/master/image-20230607100210540.png)
>
> 可以看到，非阻塞IO模型中，用户进程在第一个阶段是非阻塞，第二个阶段是阻塞状态。虽然是非阻塞，但性能并没有得到提高。而且忙等机制会导致CPU空转，CPU使用率暴增。
>
> 
>
> **解释一下I/O多路复用模型？** 
>
> I/O多路复用是指利用单个线程来同时监听多个Socket ，并在某个Socket可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。目前的I/O多路复用都是采用的epoll模式实现，它会在通知用户进程Socket就绪的同时，把已就绪的Socket写入用户空间，不需要挨个遍历Socket来判断是否就绪，提升了性能。
>
> 其中Redis的网络模型就是使用I/O多路复用结合事件的处理器来应对多个Socket请求，比如，提供了连接应答处理器、命令回复处理器，命令请求处理器；
>
> 在Redis6.0之后，为了提升更好的性能，在命令回复处理器使用了多线程来处理回复事件，在命令请求处理器中，将命令的转换使用了多线程，增加命令转换速度，在命令执行的时候，依然是单线程
>
> 
>
> **IO多路复用**：是利用单个线程来同时监听多个Socket ，并在某个Socket可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。
>
> 阶段一：
>
> ①用户进程调用select，指定要监听的Socket集合
>
> ②内核监听对应的多个socket
>
> ③任意一个或多个socket数据就绪则返回readable
>
> ④此过程中用户进程阻塞
>
> 阶段二：
>
> ①用户进程找到就绪的socket
>
> ②依次调用recvfrom读取数据
>
> ③内核将数据拷贝到用户空间
>
> ④用户进程处理数据
>
> ![image-20230607101135838](https://gitee.com/tjlxy/img/raw/master/image-20230607101135838.png)
>
> **IO多路复用**是利用单个线程来同时监听多个Socket ，并在某个Socket可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。不过监听Socket的方式、通知的方式又有多种实现，常见的有：
>
> lselect
>
> lpoll
>
> lepoll
>
> 差异：
>
> uselect和poll只会通知用户进程有Socket就绪，但不确定具体是哪个Socket ，需要用户进程逐个遍历Socket来确认
>
> uepoll则会在通知用户进程Socket就绪的同时，把已就绪的Socket写入用户空间

### 3.Redis相比Memcached有哪些优势

1. 数据类型

   - Memcached所有的值均是简单的字符串，Redis支持更为丰富的数据类型，支持string(字符串)，list(列表)，Set(集合)、Sorted Set(有序集合)、Hash(哈希)等。

2. 持久化

   - Redis支持数据落地持久化存储，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 memcache不支持数据持久存储 。

3. 集群模式

   - Redis提供主从同步机制，以及 Cluster集群部署能力，能够提供高可用服务。Memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据

4. 性能对比

5. 网络IO模型

   - Redis使用单线程的多路 IO 复用模型，Memcached使用多线程的非阻塞IO模式。

6. redis支持服务器端的数据操作

   - Redis相比Memcached来说，拥有更多的数据结构和并支持更丰富的数据操作，通常在Memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。

     这大大增加了网络IO的次数和数据体积。在Redis中，这些复杂的操作通常和一般的GET/SET一样高效。所以，如果需要缓存能够支持更复杂的结构和操作，那么Redis会是不错的选择。

### 4.为什么要用redis做缓存

- 高并发
  - 将部分数据缓存到redis上，避免请求数据库，导致数据库压力过大
- 高性能
  - 第一次请求数据库是从硬盘读取，速度较慢
  - 使用Redis后，直接操作内存，速度较快

### 5.为什么要用redis而不用map/guava做缓存

- 速度
- 数量
- 持久化
- 主从
- 稳定性
- 数据类型
- Redis可单独部署，多个项目之间可以共享，本地内存无法共享
- Redis有专门的管理工具可以查看缓存数据

### 6.Redis的常用场景有哪些✔

- 技术上
  - **缓存：穿透、击穿、雪崩、双写一致、持久化、数据过期、淘汰策略**
  - **分布式锁：setnx、redisson**
  - 计数器
  - **保存token：数据类型**
  - 消息队列：数据类型
  - 延迟队列：数据类型

- 业务上

  - 缓存

  - 排行榜

  - 计数器

  - 分布式会话

  - 分布式锁

  - 社交网络

  - 最新列表

  - 消息系统


### 7.Redis的数据类型有哪些

- 五种常用的数据类型
  - String
  - Hash
  - List
  - Set
  - SortSet
- 三种特殊的数据类型
  - `Bitmap`
  - `Hyperloglog`
  - `Geospatial`

### Redis大key怎么处理✔

Redis中的大key指的是在Redis中存储的某个key对应的value数据量很大的情况下可能会出现的问题和解决办法

**引发的问题**

1. 内存占用

   大key占用大量的内存资源，导致Redis实例的内存压力增加

2. 网络传输延迟

   大key的读写操作，可能会增加网络传输的延迟，影响性能

3. 持久化备份

   大key的持久化备份需要更多的磁盘空间和时间

**解决办法**

1. 把大key分割成多个小key来存储，可以减少单个key的大小，降低内存压力
2. 搭建Redis cluster 集群，把key分配到不同的hash slot槽所在的分片上，这样可以降低单个Redis节点的存储压力
3. 如果已经存在大key，可以做数据的拆分和迁移，按照业务需求和规则将大key拆分成多个小key，并分布到不同Redis实例上，然后在迁移完了之后清理调用不需要使用的大key
4. 可以考虑使用压缩算法进行压缩去减少存储空间的占用，也就是说在存储数据之前对数据进行压缩，在读取的时候进行解压缩，以节省存储空间和减少网络传输的数据量
5. 从业务层面进行分析，了解大key产生的原因，并根据需求和访问模式进行相应的优化

## 持久化

### 8.Redis持久化机制✔

- `RDB`快照 【Redis Database Backup file（Redis数据备份文件）】
  
  - **简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据（宕机会丢失最后一次快照后的数据）**
  
    Redis主动备份
  
    ```shell
    save #由Redis主进程来执行RDB，会阻塞所有命令
    bgsave #开启子进程执行RDB，避免主进程受到影响
    ```
  
    Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：
  
    ```shell
    # 900秒内，如果至少有1个key被修改，则执行bgsave 
    save 900 1  
    save 300 10  
    save 60 10000 
    ```
  
    
  
- `AOF`追加文件【Append Only File（追加文件）】
  
  - 将redis中所有写指令记录写下来，以日志的方式追加后面
  
    **就是说当redis操作写命令的时候，都会存储这个文件中， 当redis实例宕机恢复数据的时候，会从这个文件中再次执行一遍命令来恢复数据**
  
  要在Redis中启用AOF（Append Only File）持久化，您可以按照以下步骤进行操作：
  
  1. 打开 Redis 配置文件。默认情况下，配置文件位于 `/etc/redis/redis.conf`。
  
     ```shell
     sudo nano /etc/redis/redis.conf
     ```
  
  2. 在配置文件中找到 `appendonly` 项，并将其设置为 `yes`，即打开AOF持久化。
  
     ```
     appendonly yes
     ```
  
  3. 如果您希望每次更新都立即写入磁盘，可以将 `appendfsync` 设置为 `always`。这样会降低性能，但会提供更高的持久化保证。
  
     ```
     appendfsync always
     ```
  
     如果您希望在后台每秒钟同步一次，可以将 `appendfsync` 设置为 `everysec`。
  
     ```
     appendfsync everysec
     ```
  
  4. 保存并关闭配置文件。
  
  5. 重新启动 Redis 服务以使更改生效。
  
     ```shell
     sudo systemctl restart redis
     ```
  
  现在，Redis已经启用了AOF持久化功能。Redis会将每个写命令追加到AOF文件中，以确保数据的持久化存储。在服务器重新启动时，Redis将通过重播AOF文件来还原数据。请注意，启用AOF持久化可能会增加系统的磁盘IO负载。

RDB因为是二进制文件，在保存的时候体积也是比较小的，它恢复的比较快，但是它有可能会丢数据，我们通常在项目中也会使用AOF来恢复数据，虽然AOF恢复的速度慢一些，但是它丢数据的风险要小很多，在AOF 文件中可以设置刷盘策略，我们当时设置的就是每秒批量写入一次命令

### 9.如何选择合适的持久化方式  

- 数据不敏感
  - 可以关闭持久化
- 数据比较重要
  - 使用`rdb`
- 做内存数据库，使用Redis的持久化
  - `rdb+aof`

### 10.Redis持久化数据和缓存怎么做扩容

- 如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。
- 如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。

## 过期键的删除策略、淘汰策略

### 11.Redis过期键的删除策略✔

- 定时删除
  - 过期时间到来时，对其执行删除
  - 对CPU不友好，对内存友好
  
- **惰性删除**

  在设置该key过期时间后，我们不去管它，当需要该key 时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该key。

  - 当需要该key时，检查是否过期
  - 对内存不友好，对CPU友好

- **定期删除**

  就是说每隔一段时间，我们就对一些key进行检查，删除里面过期的key

  1、slow模式是定时任务

  2、fast模式执行频率不固定

  - 每隔一段时间，对key进行检查
  - 双刃剑
    - 可以通过限制删除操作执行的时长和频率来减少删除操作对Cpu的影响。另外定期删除，也能有效释放过期键占用的内存
    - 难以确定删除操作执行的时长和频率

惰性删除	+	定期删除两种策略进行配合使用。

### 12.Redis key的过期时间和永久有效分布怎么设置

- expire
- pexpire

### 13.Redis内存淘汰策略✔（缓存过多，内存是有限的，内存被占满了怎么办）

当Redis中的内存不够用时，此时在向Redis中添加新的key，那么Redis就会按照某一种规则将内存中的数据删除掉，这种数据的删除规则被称之为内存的淘汰策略。

Redis支持8种不同策略来选择要删除的key：

1. noeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。
2. volatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰
3. allkeys-random：对全体key ，随机进行淘汰。
4. volatile-random：对设置了TTL的key ，随机进行淘汰。
5. allkeys-lru： 对全体key，基于LRU算法进行淘汰
6. volatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰
7. allkeys-lfu： 对全体key，基于LFU算法进行淘汰
8. volatile-lfu： 对设置了TTL的key，基于LFU算法进行淘汰

> **LRU**（**L**east **R**ecently **U**sed）最近最少使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。
>
> **LFU**（**L**east **F**requently **U**sed）最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。
>
> **数据淘汰策略-使用建议**
>
> 1.优先使用 allkeys-lru 策略。充分利用 LRU 算法的优势，把最近最常访问的数据留在缓存中。如果业务有明显的冷热数据区分，建议使用。
>
> 2.如果业务中数据访问频率差别不大，没有明显冷热数据区分，建议使用 allkeys-random，随机选择淘汰。
>
> 3.如果业务中有置顶的需求，可以使用 volatile-lru 策略，同时置顶数据不设置过期时间，这些数据就一直不被删除，会淘汰其他设置过期时间的数据。
>
> 4.如果业务中有短时高频访问的数据，可以使用 allkeys-lfu 或 volatile-lfu 策略。、
>
> **关于数据淘汰策略其他的面试问题**
>
> 1.数据库有1000万数据 ,Redis只能缓存20w数据, 如何保证Redis中的数据都是热点数据 ? 
>
> 使用allkeys-lru(挑选最近最少使用的数据淘汰)淘汰策略，留下来的都是经常访问的热点数据
>
> 2.Redis的内存用完了会发生什么？
>
> 主要看数据淘汰策略是什么？如果是默认的配置（ noeviction ），会直接报错



- ` allkeys-lru：`移除最近最少使用的key

## 缓存异常

### 14.如何保证缓存与数据库双写时的数据一致性✔❤

当修改了数据库的数据也要同时更新缓存的数据，缓存和数据库的数据要保持一致

读操作：

- 缓存命中，直接返回；缓存未命中查询数据库，写入缓存，设定超时时间

写操作：

- 延迟双删【有脏数据风险】

  - 先删除缓存，后更新数据库

  - 先更新数据库，后删除缓存

    延迟双删，如果是写操作，我们先把缓存中的数据删除，然后更新数据库，最后再延时删除缓存中的数据，其中这个延时多久不太好确定，在延时的过程中可能会出现脏数据，并不能保证强一致性，所以没有采用它。

- **Redisson读写锁【强一致、性能低】**

  在读的时候添加共享锁，可以保证读读不互斥，读写互斥。当我们更新数据的时候，添加排他锁，它是读写，读读都互斥，这样就能保证在写数据的同时是不会让其他线程读数据的，避免了脏数据。这里面需要注意的是读方法和写方法上需要使用同一把锁才行。
  排他锁底层使用也是setnx，保证了同时只能有一个线程操锁住的方法

  - 强一致性的，采用Redisson提供的读写锁

    ①共享锁：读锁readLock，加锁之后，其他线程可以共享读操作   

    ②排他锁：独占锁writeLock也叫，加锁之后，阻塞其他线程读写操作

- **异步的方案同步的数据**【最终一致】

  - 允许延时一致的业务，采用异步通知

    ①使用MQ中间件，更新数据之后，通知缓存删除

    - 数据库写入：当需要对数据库进行写操作时，首先更新数据库中的数据。
    - 发送消息：在数据库数据写入成功后，发送一条消息到消息队列。消息中包含了被更新的数据的标识符或其他必要信息。
    - 消费消息：消息队列中有一个消费者，负责监听并消费这些消息。一旦消费者接收到消息，它将根据消息中的信息执行相应的操作。
    - 更新 Redis 缓存：消费者从消息中获取到被更新的数据标识符后，它将根据标识符从数据库中读取最新的数据，并将这个数据更新到 Redis 缓存中，确保缓存与数据库保持一致。
  
    通过以上步骤，可以将 Redis 缓存与数据库的数据保持同步。当数据库数据发生变化时，消息队列中的消息将触发消费者执行相应的操作，以更新 Redis 缓存中对应的数据。
  
    ②利用canal中间件，不需要修改业务代码，部署一个canal服务。canal服务把自己伪装成mysql的一个从节点，当mysql数据更新以后，canal会读取binlog数据，然后在通过canal的客户端获取到数据， 更新缓存即可。
  
  



### 17.什么是缓存击穿✔❤

- 高并发访问，某个热点的key失效，无数的请求访问，引起数据库的压力并发。

  就是说给某一个key设置了过期时间，当key过期的时候，恰好这时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端 DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把 DB 压垮。

- 解决方案
  
  1. 互斥锁
  
     - 当缓存失效时，不立即去load db，先使用如 Redis 的 setnx 去设置一个互斥锁，当操作成功返回时再进行 load db的操作并回设缓存，否则重试get缓存的方法
     - 优点：强一致
     - 缺点：性能差
  
  2. 设置永不过期
  
     1. 物理不过期，针对热点key不设置过期时间
  
     2. 逻辑过期
  
        - ①：在设置key的时候，设置一个过期时间字段一块存入缓存中，不给当前 key设置过期时间 
  
          ②：当查询的时候，从redis取出数据后判断时间是否过期 
  
          ③：如果过期则开通另外一个线程进行数据同步，当前线程正常返回数据， 这个数据不是最新
  
        - 优点：高可用，性能优
  
        - 缺点：不能保证数据绝对一致

### 18.什么是缓存穿透✔

- 缓存中不存在，数据库中也不存在

  就是说查询一个不存在的数据，mysql查询不到数据也不会直接写入缓存，就会导致每次请求查数据库

- 解决方案
  
  1. 缓存空数据
  
     - 查询返回的数据为空，仍把这个空结果进行缓存，将无效的key存放进redis中
     - 优点：实现简单，
     - 缺点：销毁内存，可能发送不一致的问题
  
  2. 使用布隆过滤器
  
     - 查询布隆过滤器，不存在，直接返回，存在（缓存预热时，预热布隆过滤器）查Redis，命中直接放回结果，查不到，查数据库，查到结果，存到Redis并返回结果。
  
       布隆过滤器主要是用于检索一个元素是否在一个集合中。
  
     - 优点：内存占用较小，没有多余key
  
     - 缺点：实现复制，存在误判

### 19.什么是缓存雪崩✔

- 某一个时刻出现大规模的key失效或Redis宕机，导致大量请求到达数据库，带来巨大压力

  就是说设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB 瞬时压力过重雪崩。与缓存击穿的区别： 雪崩是很多key，击穿是某一个key缓存。

- 解决方案
  - **给不同的key的TTL添加随机值**（主要）
    - 缓存失效时间分散开，比如可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件
  - 利用Redis集群提高服务的可用性
  - 给缓存业务添加降级限流策略
  - 给业务添加多级缓存

注意：**降级限流可做为系统的保底策略，适用于穿透、击穿、雪崩**

### 20.什么是缓存预热

- 指系统上线后，提前将相关的缓存数据加载到缓存系统

### 21.什么是缓存降级

- 在缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。  

## 线程模型

### 22.Redis为何选择单线程

- Redis是基于内存操作，执行速度非常快，Redis真正的性能瓶颈在于网络I/O
- 选择单线程的原因
  1. 避免过多的上下文切换开销
     - 如果是单线程则可以规避进程内频繁的线程切换开销，因为程序始终运行在进程中单个线程内，没有多线程切换的场景。
  2. **简单可维护**
     - 如果 Redis使用多线程模式，那么所有的底层数据结构都必须实现成线程安全的，这无疑又使得 Redis的实现变得更加复杂。
  3. **避免同步机制的开销**
     - 如果 Redis选择多线程模型，又因为 Redis是一个数据库，那么势必涉及到底层数据同步的问题，则必然会引入某些同步机制，比如锁，而我们知道 Redis不仅仅提供了简单的 key-value 数据结构，还有 list、set 和 hash 等等其他丰富的数据结构，而不同的数据结构对同步访问的加锁粒度又不尽相同，可能会导致在操作数据过程中带来很多加锁解锁的开销，增加程序复杂度的同时还会降低性能。

### 23.Redis真的是单线程

- Redis6.0引入多线程I/O，只是用来处理网络数据的读写和协议的解析，而执行命令依旧是单线程。  

### 24.Redis6.0为何引入多线程

- Redis的单线程模式会导致系统消耗很多CPU，在网络I/O上从而降低吞吐量

### 25.Redis6.0采用多线程后，性能提升效果如何

### 26.介绍下Redis的线程模型

### 27.Redis 6.0 多线程的实现机制

### 28.Redis6.0开启多线程后，是否会存在线程并发安全问题

（不考虑线程安全问题）

- Redis多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行

### 29.Redis6.0与Memcached多线程模型的对比

- 相同点：都采用了Master线程-worker线程的模型
- 不同点
  - Memcached执行逻辑也是在worker线程里，模型更加简单，符合线程隔离
  - Redis执行逻辑交给Master线程，增加了模型复杂度，解决了线程并发安全等问题

## 事务

### 30.Redis事务的概念

1. Redis事务中如果有某一条命令执行失败，之前的命令不会回滚，其后的命令仍然会被继续执行。 鉴于这个原因，所以**说Redis的事务严格意义上来说是不具备原子性的**。
2. Redis事务中所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 
3. 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。**然而如果网络中断事件是发生在客户端执行EXEC命令之后，那么该事务中的所有命令都会被服务器执行**。  

### 31.Redis事务的三个阶段

- `multi`开启事务
- 大量指令入队
- `exec`执行事务块内命令（截止此处，一个事务已经结束）
- `discard`取消事务
- `watch`监视一个或多个key，如果事务执行前key被改动，事务将打断，`unwatch`取消监视。
- 【如果执行过程中，服务端收到其他命令请求，会将请求放入到队列中排队】

### 32.Redis事务相关命令

- `Watch`监控一个或多个键，持续到EXEC命令
- `Multi`
- `Exec`
- `Discard`
- `UnWatch`取消对所有key的监控

### 33.Redis事务支持隔离性吗

- Redis是单线程程序，Redis事务总数带有隔离性的

### 34.Redis为什么不支持事务回滚

- **Redis命令只会因为错误的语法而失败**，或是命令用在了错误类型的键上面，失败的命令是由编程错误造成的，而这些错误应该在开发过程中被发现，而不应该出现在生产环境中

### 35.Redis事务其他实现

## 主从、哨兵、集群

### 36.Redis常见使用方式有哪些✔

- 单副本
  - 数据量少适用
- **多副本（主从）**
  - 可用性不高，基本不用（master节点挂掉之后需要手动指定新的master）
- **Sentinel（哨兵）**
  - 数据量不是很多，集群规模不是很大，需要自动容错的时候适用
- **Cluster（Redis分片集群）**
  - 海量数据+高并发+高可用的场景
- 自研

### 37.介绍下Redis的单副本

- 单个Redis节点部署架构
- 优点
  - 部署简单
  - 性价比高
  - 高性能
- 缺点
  - 不能保证数据的可靠性，没有备用节点
  - 适合操作命令简单、排序、计算较少的场景

### 38.介绍下Redis多副本（主从）✔

- 主从部署架构，提高数据持久化和备份策略
- 优点
  - 可靠性高
  - 读写分离
- 缺点
  - 故障恢复复杂
  - 主库写能力和存储能力受到单机的线程

### 介绍一下主从同步✔

单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，可以搭建主从集群，实现读写分离。一般都是一主多从，主节点负责写数据，从节点负责读数据，主节点写入数据之后，需要把数据同步到从节点中

### 主从同步数据的流程✔

主从同步分为了两个阶段，一个是全量同步，一个是增量同步 

全量同步是指从节点第一次与主节点建立连接的时候使用全量同步，流程是这样的：

第一：从节点请求主节点同步数据，其中从节点会携带自己的replication id 和offset偏移量。

 第二：主节点判断是否是第一次请求，主要判断的依据就是，主节点与从节点是否是同一个replication id，如果不是，就说明是第一次同步，那主节点就会把自己的replication id和offset发送给从节点，让从节点与主节点的信息保持一致。 

第三：在同时主节点会执行bgsave，生成rdb文件后，发送给从节点去执行，从节点先把自己的数据清空，然后执行主节点发送过来的rdb文件，这样就保持了一致

当然，如果在rdb生成执行期间，依然有请求到了主节点，而主节点会以命令的方式记录到缓冲区，缓冲区是一个日志文件，最后把这个日志文件发送给从节点，这样就能保证主节点与从节点完全一致了，后期再同步数据的时候，都是依赖于这个日志文件，这个就是全量同步

增量同步指的是，当从节点服务重启之后，数据就不一致了，所以这个时候，从节点会请求主节点同步数据，主节点还是判断不是第一次请求，不是第一次就获取从节点的offset值，然后主节点从命令日志中获取offset值之后的数据，发送给从节点进行数据同步

###  39.介绍下Redis Sentinel（哨兵）✔

- 优点
  - 部署简单
  - 高可用
  - 可扩展
  - 可以实现Sentinel监控
- 缺点
  - 部署相比中从模式要复杂
  - 资料浪费
  - 不能解决读写分离问题，实现起来相对复杂

### 怎么保证Redis的高并发高可用✔

首先可以搭建主从集群，再加上使用redis中的哨兵模式，哨兵模式可以实现主从集群的自动故障恢复，里面就包含了对主从服务的监控、自动故障恢复、通知；如果master故障，Sentinel会将一个slave提升为master。 

当故障实例恢复后也以新的master为主；同时Sentinel也充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端，所以一般项目都会采用哨兵的模式来保证redis的高并发高可用

### 使用redis是单点还是集群，哪种集群✔

我们当时使用的是主从（1主1从）加哨兵。一般单节点不超过10G内存，如果Redis内存不足则可以给不同服务分配独立的Redis主从节点。尽量不做分片集群。因为集群维护起来比较麻烦，并且集群之间的心跳 检测和数据通信会消耗大量的网络带宽，也没有办法使用lua脚本和事务

### redis集群脑裂，该怎么解决呢✔

这个在项目很少见，不过脑裂的问题是这样的，我们现在用的是redis的哨兵模式集群的 

有的时候由于网络等原因可能会出现脑裂的情况，就是说，由于redis master节点和redis salve节点和sentinel处于不同的网络分区，使得sentinel没有能够心跳感知到master，所以通过选举的方式提升了一个salve为master， 这样就存在了两个master，就像大脑分裂了一样，这样会导致客户端还在 old master那里写入数据，新节点无法同步数据，当网络恢复后，sentinel会 将old master降为salve，这时再从新master同步数据，这会导致old master中 的大量数据丢失。

关于解决的话，我记得在redis的配置中可以设置：第一可以设置最少的salve 节点个数，比如设置至少要有一个从节点才能同步数据，第二个可以设置主从数据复制和同步的延迟时间，达不到要求就拒绝请求，就可以避免大量的数据丢失

### 40.介绍下Redis Cluster （分片集群）✔

- 优点
  - 节点数据共享
  - 可扩展
  - 高可用
  - 降低运维成本
- 缺点
  - 实现复杂
  - 。。

### redis的分片集群有什么作用✔

分片集群主要解决的是，海量数据存储的问题，集群中有多个 master，每个master保存不同数据，并且还可以给每个master设置多个slave 节点，就可以继续增大集群的高并发能力。同时每个master之间通过ping监测彼此健康状态，就类似于哨兵模式了。当客户端请求可以访问集群任意节点，最终都会被转发到正确节点

### Redis分片集群中数据是怎么存储和读取的✔

Redis 集群引入了哈希槽的概念，有 16384 个哈希槽，集群中每个主节点绑定了一定范围的哈希槽范围， key通过 CRC16 校验后对 16384 取模来决定放置哪个槽，通过槽找到对应的节点进行存储。 

取值的逻辑是一样的

### 41.介绍下Redis自研

- 优点
  - 高可靠、高可用性
  - 自主可控性高
  - 贴切业务实际需求，可缩性好，兼容性好
- 缺点
  - 实现复杂，开发成本高
  - 需要建立配套设施
  - 维护成本高

### 42.Redis高可用方案具体怎么实施✔

- 使用官方推荐的哨兵（sentinel）机制
- 四个功能
  - 集群监控，负责监控Redis master和slave进程是否正常工作。
  - 消息通知，如果某个Redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
  - 故障转移，如果master node挂掉了，会自动转移到slave node上。
  - 配置中心，如果故障转移发生了，通知client客户端新的master地址。

### 43.了解主从复制原理吗✔❤

1. 主从架构的核心原理
   - master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB文件生成完毕之后，master会将这个RDB发送给 slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中。然后master会将内存中缓存的写命令发送给slave，slave也会同步这些数据。  
2. 主从复制的断点续传
3. 无磁盘化复制
4. 过期key处理
   - slave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。

### 44.由于主从延迟导致读取到过期数据怎么处理

- scan（相当于访问该key）

### 45.主从复制的过程中，如果因为网络原因停止复制了会怎么样

- 断点续传，可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份

### 46.Redis主从架构数据会丢失吗，为什么

- 异步复制导致数据库丢失
- 脑裂导致的数据丢失

### 47.如何解决主从架构数据丢失的问题

- `min-skaves-to-write 1`
- `min-slaves-max-lag 10`
- 至少有一个slave，数据复制和同步的延迟不能超过10秒，否则master就不会再接收任何请求了

### 48.Redis哨兵是怎么工作的

### 49.故障转移时会从剩下的slave选举一个新的master，被选举为master的标准是什么

- 跟master断开连接的时长
- slave优先级
- 复制offset
- run id

### 50.同步配置的时候其他哨兵根据什么更新自己的配置呢

### 51. 为什么Redis哨兵集群只有2个节点无法正常工作

哨兵集群必须部署2个以上节点。

如果两个哨兵实例，即两个Redis实例，一主一从的模式。

则Redis的配置quorum=1，表示一个哨兵认为master宕机即可认为master已宕机。

但是如果是机器1宕机了，那哨兵1和master都宕机了，虽然哨兵2知道master宕机了，但是这个时候，需要majority，也就是大多数哨兵都是运行的，2个哨兵的majority就是2（2的majority=2，3的majority=2，5的majority=3，4的majority=2），2个哨兵都运行着，就可以允许执行故障转移。

但此时哨兵1没了就只有1个哨兵了了，此时就没有majority来允许执行故障转移，所以故障转移不会执行。

### 52.Redis cluster中是如何实现数据分布式的？这种方式有什么优点

### 53.Redis cluster节点间通信是什么机制

## 分布式问题

### 54.什么是分布式锁？为什么用分布式锁

锁在程序中的作用就是同步工具，保证共享资源在同一时刻只能被一个线程访问，Java中的锁我们都很熟悉了，像synchronized 、Lock都是我们经常使用的，但是Java的锁只能保证单机的时候有效，分布式集群环境就无能为力了，这个时候我们就需要用到分布式锁。

分布式锁，顾名思义，就是分布式项目开发中用到的锁，可以用来控制分布式系统之间同步访问共享资源。

思路是：在整个系统提供一个**全局、唯一**的获取锁的“东西”，然后每个系统在需要加锁时，都去问这个“东西”拿到一把锁，这样不同的系统拿到的就可以认为是同一把锁。至于这个“东西”，可以是Redis、Zookeeper，也可以是数据库。

### 55.常见的分布式锁有哪些解决方案

实现分布式锁目前有三种流行方案，即基于关系型数据库、Redis、ZooKeeper 的方案

### 56.Redis实现分布式锁✔

> 在redis中提供了一个命令setnx(SET if not exists)
>
> 由于redis的单线程的，用了命令之后，只能有一个客户端对某一个key设置值，在没有过期或删除key的时候是其他客户端是不能设置这个key的
>
> **如何控制Redis实现分布式锁有效时长呢？**
>
> redis的setnx指令不好控制这个问题，我们当时采用的redis的一个框架redisson实现的。
>
> 在redisson中需要手动加锁，并且可以控制锁的失效时间和等待时间，当锁住的一个业务还没有执行完成的时候，在redisson中引入了一个看门狗机制，就是说每隔一段时间就检查当前业务是否还持有锁，如果持有就增加加锁的持有时间，当业务执行完成之后需要使用释放锁就可以了
>
> 还有一个好处就是，在高并发下，一个业务有可能会执行很快，先客户1持有锁的时候，客户2来了以后并不会马上拒绝，它会自旋不断尝试获取锁，如果客户1释放之后，客户2就可以马上持有锁，性能也得到了提升。
>
> **redisson实现的分布式锁是可重入的吗？**
>
> 是可以重入的。这样做是为了避免死锁的产生。这个重入其实在内部就是判断是否是当前线程持有的锁，如果是当前线程持有的锁就会计数，如果释放锁就会在计算上减一。在存储数据的时候采用的hash结构，大key可以按照自己的业务进行定制，其中小key是当前线程的唯一标识，value是当前线程重入的次数
>
> **redisson实现的分布式锁能解决主从一致性的问题吗**
>
> 这个是不能的，比如，当线程1加锁成功后，master节点数据会异步复制到slave节点，此时当前持有Redis锁的master节点宕机，slave节点被提升为新的master节点，假如现在来了一个线程2，再次加锁，会在新的master节点上加锁成功，这个时候就会出现两个节点同时持有一把锁的问题。
>
> 我们可以利用redisson提供的红锁来解决这个问题，它的主要作用是，不能只在一个redis实例上创建锁，应该是在多个redis实例上创建锁，并且要求在大多数redis节点上都成功创建锁，红锁中要求是redis的节点数量要过半。这样就能避免线程1加锁成功后master节点宕机导致线程2成功加锁到新的master节点上的问题了。
>
> 但是，如果使用了红锁，因为需要同时在多个节点上都添加锁，性能就变的很低了，并且运维维护成本也非常高，所以，我们一般在项目中也不会直接使用红锁，并且官方也暂时废弃了这个红锁
>
> **如果业务非要保证数据的强一致性，这个该怎么解决呢？**
>
> redis本身就是支持高可用的，做到强一致性，就非常影响性能，所以，如果有强一致性要求高的业务，建议使用zookeeper实现的分布式锁，它是可以保证强一致性的。

### 57.了解RedLock吗

### 58.RedLock的原理

## 其他

### 59.Redis如何做内存优化

- 控制key的数量
- 缩减键值对象（key、value的长度）
- 编码优化

### 60.如果现在有个读超高并发的系统，用Redis来抗住大部分读请求，你会怎么设计

### 怎么使用Redis实现一个延时队列✔

**延时队列是一种特殊类型的消息队列，它允许把消息发送到队列中，但不立即投递给消费者，而是在一定时间后再将消息投递给消费者**，所以，它通常用于需要在未来的某个时间执行某个任务的场景，比如订单的超时处理，定时任务等等。

在Redis里面，可以使用Zset这个有序集合来实现延迟队列，具体的实现方式可以分为几个步骤：

1. 使用ZADD命令把消息添加到sorted set中，并将当前时间作为score，并且把当前的时间作为score
2. 启动一个消费者线程，使用ZRANGEBYSCORE命令获取定时从Zset中获取当前时间之前的所有消息
3. 消费者处理完成以后，可以从有序集合中删除这些消息

通过这种方式虽然可以实现延迟队列，但是消费端需要不断的向Redis去发起轮询，会存在一下这几个问题：

1. 轮询存在时间间隔，所以延时消息的实际消费时间会大于设定时间
2. 大量的轮询动作会对Redis服务器造成压力，所以如果需要使用延迟消息，很多MQ组件都支持这样一个能力



