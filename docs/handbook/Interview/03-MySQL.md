# MySQL



## 索引

### 1.索引是什么（无过滤不索引）✔

- 数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中的数据

  > 主要是用来提高数据检索的效率，降低数据库的IO成本，同时通过索引列对数据进行排序，降低数据排序的成本，也能降低了CPU的消耗

- 是一个文件，占据物理空间

### 2.索引有哪些优缺点✔

- 优点
  - **加快了数据的检索速度**
  - 使用索引，可以在查询过程中，使用隐藏优化器，提高系统性能
- 缺点
  - 时间方面：创建索引和维护索引（添加、删除、修改）要耗费时间
  - 空间方面：占据物理内存
  > 1. 会占用空间
  > 2. 更新时会级联更新索引
  > 3. 高并发写影响性能

### 数据库索引的原理

1. 以mysql为例，默认引擎InnoDB使用了b+树实现索引，在索引查找时,实现了log（n）的时间复杂度
2. 聚簇索引记录了主键id（完整数据），非聚簇索引的索引树中记录数据（索引字段+主键）
3. 在聚簇索引的叶子节点中记录了完整的值，非聚簇索引的叶子节点记录的是主键以及索引字段，如果需要完整值的话需要回表操作，即使用主键去聚簇索引中再次查找完整数据
4. 索引的叶子节点以链表的形式存储，方便顺序查找和排序

### 3.MySQL有哪几种索引类型✔

- 存储结构：BTree、Hash、full-index、R-Tree
- 应用层面：
  - 普通索引：一个索引只能包含单个列，一个表可以有多个单列索引
  - 唯一索引：索引列的值必须唯一，但允许有空值
  - 复合索引：多列值组成一个索引，用于组合搜索，效率大于搜索合并
  - 聚簇索引：在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。
  - 非聚簇索引

### 4.说一说索引的底层实现✔

- B树
  - 节点排序
  - 一个节点可以存放多个元素，多个元素也排序了
- B+树
  - 拥有B树的特点
  - 叶子节点之间有指针
  - 非叶子节点上的元素在叶子节点上都冗余了，也就是叶子节点中存储了所有的元素，并且排好顺序，B+树查找效率更加稳定
  - 在进行范围查询的时候，B+树效率更高，因为B+树都在叶子节点存储，并且叶子节点是一个双向链表
- Hash
  - 将所有的哈希码存储在索引中
  - 只有精确匹配所有列的查询才有效

### Hash索引和B+树索引的区别✔

Hash索引的结构和HashMap的结构有点类似，**键值key通过hash映射到一个bucket桶里面**，桶指的是一个**能存储一条或多条记录的存储单位**，**一个桶的结构包含了一个内存指针的数组**，**桶中的每行数据都会指向下一行**，**形成一个链表结构**，当遇到Hash冲突的时候，会在桶中进行键值的查找，采用Hash进行检索的效率非常高，基本上一次检索就可以找到对应的数据

B+Tree索引结构是一个多路平衡树，**特点是根节点和分支只保存索引**，**所有的数据都存储在叶子节点**，叶子节点会包含所有的关键字，以及指向数据记录的指针，并且叶子节点本身是根据关键字的大小从小到大顺序组成一个双向链表，基于这样的特点，使得B+Tree树的高度在3~4层左右，就能够实现千万级的数据存储，以及适合对于组件范围的查找和分页查找

| Hash索引                                             | B+Tree索引                                 |
| ---------------------------------------------------- | ------------------------------------------ |
| 哈希表结构                                           | 多路平衡树结构                             |
| 在等值查询上具有较好的性能，对范围查询和排序操作较差 | 在范围查询和排序操作上更加高效             |
| **对磁盘存储的利用效率不高（随机存储）**             | **节点是有序的，有利于磁盘的顺序访问**     |
| 在插入和删除操作上相对比较简单                       | 插入和删除操作更复杂（需要维护树的平衡性） |

### B树和B+树的理解✔

B树和B+树都是多路平衡树，能够在一个比较矮的层高中去存储大量的数据

**B Tree**

1. 在B树中，每个节点都包含索引及数据，所以树的层高相对来说会高一些
2. 同时在进行数据查找的时候，由于数据是存储在每个节点的，所以极端情况下要遍历整个树才能找到数据，所以查询时间的稳定性较差
3. B树的所有叶子节点都在同一层意味着从根节点到每个叶子节点的距离相等，这样可以保证无论访问那个叶子节点，时间复杂度都是O(logn)

**B+Tree**	是在B树上做的一个优化

1. B+树的非叶子节点只存储索引，所以有数据记录保存到叶子节点中，这样可以更好的缩小树的层高，提高查询效率
2. B+树的所有叶子节点通过一个双向指针连接，使得范围查找的效率更高

### 5.为什么索引结构默认使用B+Tree，而不是B-Tree，Hash，二叉树，红黑树✔

- B+Tree
  - B+Tree的内部节点没有执行关键字的具体信息的指针，内部节点相对B树更小，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了
  - **B+Tree的数据都存储在叶子结点中**，这使得每个节点可以存储更多的索引值，整棵树更矮，减少了I/O次数，从而降低了磁盘读写代价。
  - B+Tree阶数更多，路径更短
  - **B+树的查询效率更加稳定**。在B+树中，顺序检索比较明显，随机检索时，由于所有数据都存储在叶子节点上，无论关键字在哪个位置，查询效率都相同。因此，时间复杂度固定为O(log n)。而在B-树中，由于非叶子节点也可能存储数据，查询时间复杂度不固定，与关键字在树中的位置有关
- Hash：
  - **没有顺序，io复杂度高**
  - **不支持范围查询**
  - 不支持部分索引列的匹配
  - 。。。
- 二叉树：不能自平衡
- 红黑树：是一颗平衡二叉树，数据量大的时候，树的深度也很深，IO代价高

### 6.讲一讲聚簇索引（聚集索引）与非聚簇索引（二级索引）✔

- 聚簇索引：B+Tree叶子节点存储了整行数据（主键索引），有且只有一个，一般情况下主键在作为聚簇索引的

> 聚集索引选取规则:
>
> 如果存在主键，主键索引就是聚集索引。
>
> 如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚集索引。
>
> 如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引。

- 非聚簇索引：数据与索引分开存储，B+Tree叶子节点存储了主键的值，可以有多个，一般我们自己定义的索引都是非聚簇索引

### 什么是回表✔

当查询需要返回的列不在索引页中时，就需要进行回表查询。

回表是和聚簇索引、非聚簇索引是有关系的，回表的意思就是**查询并需要返回非索引列的值时通过二级索引找到对应的主键值，然后再通过主键值找到聚集索引中所对应的整行数据**，这个过程就是回表

> 当我们在表上创建了非聚集索引（通常是B树索引）时，该索引仅包含索引列的值和指向相应行的引用。当使用这个索引来执行查询并需要返回非索引列的值时，MySQL需要通过这个引用进行额外的查找，去主键索引或聚集索引中找到完整的行数据，这个过程就被称为回表。

### 什么是覆盖索引✔

覆盖索引是指select查询语句使用了索引，**在返回的列，必须在索引中全部能够找到**，如果我们使用id查询，它会直接走聚集索引查询，一次索引扫描，直接返回数据，性能高。（覆盖索引（Covering Index）是指一个索引包含了查询所需的所有列，而无需回表到表格中进行进一步的查找。）

如果按照二级索引查询数据的时候，返回的列中没有创建索引，有可能会触发回表查询，尽量避免使用select *，尽量在返回的列中都包含添加索引的字段

> | id   | name | gender | createdate |
> | ---- | ---- | ------ | ---------- |
> | 2    | Arm  | 1      | 2021-01-01 |
> | 3    | Lily | 0      | 2021-05-01 |
> | 5    | Rose | 0      | 2021-02-14 |
> | 6    | Zoo  | 1      | 2021-06-01 |
> | 8    | Doc  | 1      | 2021-03-08 |
> | 11   | Lee  | 1      | 2020-12-03 |
>
> - id为主键，默认是主键索引
>
> - name字段为普通索引
>
> ```sql
> select * from tb_user where id = 1						#覆盖索引
> select id，name from tb_user where name = ‘Arm’			#覆盖索引
> select id，name，gender from tb_user where name = ‘Arm’	#非覆盖索引（需要回表查询）
> ```
>
> 



### 7.非聚簇索引一定会一定会回表查询吗

- 如果全部命中索引，就不必在进行回表查询

### 8.联合索引是什么？为什么需要注意联合索引中的顺序

- 联合索引：使用多个字段建立一个索引
- 注意：需要按照建立索引时的字段**顺序**挨个使用，否则无法命中索引（最左前缀原则）

### 9.讲一讲MySQL的最左前缀原则（最左匹配原则）✔

通常指的是索引的匹配方式，简单来说，**当查询语句中有多个条件，并且这些条件可以用索引进行匹配时，数据库系统会使用最左匹配原则来选择最合适的所有进行查询**。

从B+树的索引结构展开，假设存在`(a,b)`这样一个联合索引，叶子节点为`(1,1)(1,2)(2,2)-(2,5)(3,1)`，其中a字段的值是有序的`1,1,2,2,3`，b字段的值是没有顺序的`1,2,2,5,1`，但是可以发现，如果字段a匹配成功的情况下，b字段的值又是按照顺序排序的，但是这种顺序是相对的，这是因为**MySQL创建联合索引的规则是，首先会对联合索引的最左边第一个字段进行排序，在第一个字段的排序基础上在对第二个字段进行排序**，所以如果只是单纯的用`b=2`这样一个查询条件，是没有办法利用到索引的，**因此`InnoDB`的联合索引中，只有先确定了前一个值，才能确定下一个值**。

注意：

- 如果有范围查询，那么联合索引中使用范围查询的字段后的索引在该条sql中都不会起作用
- `in`,`=`允许乱序匹配，eg：存在索引`(a,b,c)` 查询语句`select * from t where c =1 and a = 2 and b = 3;`依然会使用到索引，因为底层会进行优化。

举例如下：

假设index(a,b,c)

| Where语句                                                  | 索引是否被使用                                               |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| where a = 3                                                | Y,使用到a                                                    |
| where a =  3 and b = 5                                     | Y,使用到a，b                                                 |
| where a =  3 and b = 5 and c = 4                           | Y,使用到a,b,c                                                |
| where b =  3 或者 where b = 3 and c =  4 或者 where c =  4 | N                                                            |
| where a =  3 and c = 5                                     | 使用到a， 但是c不可以，b中间断了                             |
| where a =  3 and b > 4 and c = 5                           | 使用到a和b， c不能用在范围之后，b断了                        |
| where a is  null and b is not null                         | is null 支持索引  但是is not null 不支持,所以 a 可以使用索引,但是 b不一定能用上索引（8.0） |
| where a  <> 3                                              | 不能使用索引                                                 |
| where  abs(a) =3                                           | 不能使用索引                                                 |
| where a =  3 and b like 'kk%' and c = 4                    | Y,使用到a,b,c                                                |
| where a =  3 and b like '%kk' and c = 4                    | Y,只用到a                                                    |
| where a =  3 and b like '%kk%' and c = 4                   | Y,只用到a                                                    |
| where a =  3 and b like 'k%kk%' and c =  4                 | Y,使用到a,b,c                                                |



### 10.讲一讲前缀索引

- 把很长字段的前面的公共部分作为一个索引
- 注意：order by不支持前缀索引

### 11.了解索引下推吗（减少回表次数）✔

- 在不使用ICP（索引下推）的情况下，在使用非主键索引（又叫普通索引或者二级索引）进行查询时，**存储引擎通过索引检索到数据，然后返回给MySQL服务器，服务器然后判断数据是否符合条件。**
- 在使用ICP（索引下推）的情况下，如果存在某些被索引的列的判断条件时，**MySQL服务器将这一部分判断条件传递给存储引擎**，然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器。

索引条件下推优化可以**减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。**

> 索引下推是MySQL5.6推出来的一个查询优化方案，**主要目的是减少数据库中不必要的数据读取和计算**，**原理是MySQL在执行查询时，会先根据查询条件选择合适的索引，然后将索引相关的过滤条件下推到存储引擎层执行，只将满足这些条件的行返回给MySQL服务器，减少从磁盘读取的数据量和后续的计算开销**。
>
> 在传统的查询执行中，MySQL会先从存储引擎读取满足条件的所有行，然后在MySQL服务器层应用过滤条件进行筛选。这种方式可能导致不必要的数据传输和处理，尤其是当表中的数据较大时。

### 12.怎么查看MySQL语句有没有使用到索引✔

**无过滤，不索引**（where。。。）

- `explain`

  - **`type`** ALL 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.

     性能由好到差为NULL、system、const、eq_ref、ref、range、 index、all   

    system：查询系统中的表

    const：根据主键查询

    eq_ref：主键索引查询或唯一索引查询

    ref：索引查询

    range：范围查询

    index：索引树扫描

    all：全盘扫描

  - **`possible_key`** 可能用到的索引

  - **`key`** 当前sql实际命中的索引

  - `key_len `索引占用的大小

  - `rows`估算SQL要查找到结果集需要扫描读取的数据行数，直观显示SQL的效率好坏，原则上越少越好

  - **`filtered`** 满足查询条件的百分比

  - `Extra`额外的优化建议

  | **Extra**                 | **含义**                                                     |
  | ------------------------- | ------------------------------------------------------------ |
  | Using where;  Using Index | 查找使用了索引，需要的数据都在索引列中能找到，不需要回表查询数据 |
  | Using  index condition    | 查找使用了索引，但是需要回表查询数据                         |

> 如果一条sql执行很慢的话，我们通常会使用mysql自动的执行计划explain来去查看这条sql的执行情况，比如在这里面可以通过key和key_len检查是否命中了索引，如果本身已经添加了索引，也可以判断索引是否有失效的情况，第二个，可以通过type字段查看sql是否有进一步的优化空间，是否存在全索引扫描或全盘扫描，第三个可以通过extra建议来判断，是否出现了回表的情况，如果出现了，可以尝试添加索引或修改返回字段来修复

### 13.为什么官方建议使用自增长主键作为索引

- 减少页分裂和移动的频率。（B+Tree）

### 14.如何创建索引✔

- `create table`	
- `alter table 表名 add index 索引名(列名)`
- `creat index 索引名 on 表名(列名)`

### 15.创建索引时需要注意什么✔

- 非空字段（特殊值代替）

  应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；

- 取值离散大的字段（唯一性）

  （变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；

- 索引字段越小越好（减少io）

  索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。

### 16.建索引的原则有哪些✔

- 最左前缀匹配原则
- =和in可以乱序
- 尽量选择区分度高的（字段不重复的比例）列作为索引
- **索引列不能参与计算**
- 尽量的扩展索引，不要新建索引

**补充：**

1). 针对于数据量较大，且**查询比较频繁的表建立索引**。

2). 针对于**常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引**。

3). **尽量选择区分度高的列作为索引**，尽量建立唯一索引，区分度越高，使用索引的效率越高。

4). 如果是字符串类型的字段，字段的长度较长，**可以针对于字段的特点，建立前缀索引**。

5). **尽量使用联合索引，减少单列索引**，查询时，联合索引很多时候可以覆盖索引，节省存储空间，避免回表，提高查询效率。

6). **要控制索引的数量**，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增删改的效率。

7). 如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它。当优化器知道每列是否包含NULL值时，它可以更好地确定哪个索引最有效地用于查询。

> 这个情况有很多，不过都有一个大前提，就是表中的数据要超过10万以上，我们才会创建索引，并且添加索引的字段是查询比较频繁的字段，一般也是像作为查询条件，排序字段或分组的字段这些。
>
> 还有就是，我们通常创建索引的时候都是使用复合索引来创建，一条sql的返回值，尽量使用覆盖索引，如果字段的区分度不高的话，我们也会把它放在组合索引后面的字段。 
>
> 如果某一个字段的内容较长，我们会考虑使用前缀索引来使用，当然并不是所有的字段都要添加索引，这个索引的数量也要控制，因为添加索引也会导致新增改的速度变慢。

### 17.使用索引查询一定能提高查询的性能吗

索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。  因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。

### 18.什么情况下不走索引（索引失效场景）✔

1. `!=`、`<>`
2. **类型不一致，类型转换**
3. 函数、运算符
4. `OR`
5. **模糊查询**
6. `not in`**、**`not exists`

**补充：**

1). 在符合索引中，违反最左前缀法则

如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始，并且不跳过索引中的列。

2). 范围查询，右边的列不能使用索引 。

3). 不要在索引列上进行运算操作或函数操作， 索引将失效。

4). 字符串不加单引号，造成索引失效。（MySQL的查询优化器，会自动的进行类型转换，造成索引失效）

5).以%开头的Like模糊查询，索引失效。如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。

6).在where子句中使用一些逻辑操作符，例如：`not in`**、**`not exists`、`!=`、`<>`

7).如果MySQL估计全表扫描比索引速度更快，它会选择全表扫描，不走索引 

> 比如，索引在使用的时候没有遵循最左匹配法则，第二个是，模糊查询，如果%号在前面也会导致索引失效。如果在添加索引的字段上进行了运算操作或者类型转换也都会导致索引失效。
>
> 我们之前还遇到过一个就是，如果使用了复合索引，中间使用了范围查询， 右边的条件索引也会失效 
>
> 所以，通常情况下，想要判断出这条sql是否有索引失效的情况，可以使用 explain**执行计划来分析**

## 基础

### 19.数据库的三范式是什么

1. 第一范式（1NF）：要求数据表中的每一列都必须是不可分割的单一值，并且表中的每一行都必须有唯一的标识。这意味着每个字段都是原子性的，不可再分解，而且每个记录都有一个唯一的标识符。**满足第一范式的数据库表中的每个值都是不可拆分的原子值**。

   单表（字段）拆分到不可拆分为止

   o  -张，三，街道地址方便分组 联系方式（手机号，email）

   o  -有主键，具有原子性，字段不可分割

2. 第二范式（2NF）：要求表中的每一列都必须完全依赖于主键，也就是说，如果表中有多个列作为主键，那么其它列都必须依赖于这些列中的所有列。满足第二范式的数据库表必须满足第一范式。

   每一行数据唯一性

   o   - 订单地址重复，引用其他表

   o   - 多表关联

3. 第三范式（3NF）：要求表中的每一列都必须与主键或其它列没有直接的依赖关系，也就是说，表中的每一列都必须与主键直接相关，或者与其它列间接相关，但是不能直接依赖于其它列。满足第三范式的数据库表必须满足第二范式。

   表之间关联主键依赖

   o  -单行数据中保留唯一主键，建立外键关联表


数据库三范式是设计数据库表的方法论，能够充分的利用关系型数据库把实体有机的关联起来

降低耦合度节省存储空间

### 20.MySQL支持哪些存储引擎✔

- InnoDB、MyISAM、Memory、Archive。。。
- InnoDB支持外键、事务，是**聚簇索引**，不支持全文索引，不保存表的具体行数，采用行级锁。

### InnoDB和MyISAM有什么区别✔

1. 事务支持不同

   InnoDB支持事务处理，而MyISAM不支持

2. 并发处理不同

   InnoDB支持行级锁，而MyISAM支持表级锁

3. 外键支持不同
   
   InnoDB支持外键约束，而MyISAM不支持
   
4. 性能上存在差异

   MyISAM的读取速度比InnoDB快，但是高并发环境下，InnoDB性能更好，因为InnoDB支持行级锁和事务处理，而MyISAM不支持，所有如果是读多写少的情况下，MyISAM引擎会更适合

   如果应用程序有大量并发的读取和写入操作，并且需要事务处理和数据完整性保证，那么InnoDB引擎是更好的选择。如果应用程序主要是读取操作，并且对于并发写入操作的一致性要求较低，那么MyISAM引擎可能更适合。

5. 数据安全不同

   InnoDB支持奔溃恢复和数据恢复，而MyISAM不支持，如果MySQL奔溃了，或者发生意外故障，InnoDB可以通过恢复日志来恢复数据
   
6. 索引类型不同

   InnoDB是聚簇索引（主键索引），而MyISAM是非聚簇索引（二级索引）

### 21.超键、候选键、主键、外键分别是什么

- 超建：能唯一标识元组的属性集。（候选键+主键）
- 候选键：没有冗余元素的超建
- 主键：对存储数据对象予以唯一和完整标识的数据列或属性的组合
- 外键：在一个表中存在另一个表的主键

### 22.SQL约束有哪几种✔

- `not null`
- `unique`
- `primary key`
- `foreign key`
- `check`控制字段值范围（oracel）

### 23.MySQL中的varchar和char有什么区别✔

- char是不可变字段，varchar是可变字段
- 检索效率：char>varchar

### 24.MySQL中in和exists区别

- 区别
  1. `in`：把外表和内表作`hash`连接、
  2. `exists`：对外表做`loop`循环，每次循环再对内表查询
- 效率
  - 两个大小相当的表
    - 差别不大
  - 一个较小，一个较大
    - 子查询表大的用`exists`，子查询表小的用`in`
  - 无论那个表大，`not exists`都比`not in`快

### 25.drop、delete与truncate的区别✔

|              | drop             | delete         | truncate     |
| ------------ | ---------------- | -------------- | ------------ |
| **类型**     | DDL              | DML            | DDL          |
| 回滚         | 不回滚           | 回滚           | 不回滚       |
| 删除内容     | 全表、权限、索引 | 单、多行结构在 | 全表，结构在 |
| **删除速度** | 最快             | 最慢           | 较快         |

### 26.什么是存储过程？有哪些优缺点

- 一组为了完成特定功能的SQL语句集，存储在数据库中
- 优点
  - 存储过程可以重复使用，从而减少数据库开发人员的工作量
  - 存储过程位于服务器上，降低了网络传输的数据量
  - 安全性高
- 缺点
  - 开发调试差
  - 可移植性差
  - 如果带有有引用关系的对象发送改变时，受影响的存储过程、包将需要重新编译
  - 维护困难

### 27.MySQL执行查询的过程✔

- 客户端（TCP连接）
- 连接器
- 查缓存
- 分析器（Sql语法）
- 优化器（是否使用索引）
- 执行器（将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端）

> 1. 客户端通过 TCP 连接发送连接请求到 MySQL 连接器，连接器会对该请求进行权限验证及连接资源分配
> 2. 查缓存。（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。）
> 3. 语法分析（SQL 语法是否写错了）。 如何把语句给到预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义。
> 4. 优化。是否使用索引，生成执行计划。
> 5. 交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。

### 为什么不能用浮点型表示金额

一般在金融领域中，表示货币的精度，至少要精确的表示0.1或者0.01等货币的数值，这样在进行资金运算的时候，才能够**避免精度丢失，造成用户的资金损失**，而浮点数是用二进制科学技术法表示的，这就意味着**它不能精确地表示所有的十进制小数**，可以使用浮点数进行运算，比如加减乘除，可能会产生四舍五入的错误，在大多数情况下，这种错误可能影响不大，但是在处理资金问题的场景中，这些小的错误可能会累计起来，导致最后的结果与期望的结果有明显的差距，所有为了避免这一类问题，通常推荐使用**特殊的货币类型BigDecimal表示金钱**，这样可以确保在进行算术运算的时候，能够保证精确的结果

### 为什么数据库字段建议设置为NOT NULL✔

1. **数据的完整性**

   通过把字段设置为NOT NULL，可以确保数据库中的数据完整性，**如果某个字段允许为空，那么就有可能在数据中出现不完整或不一致的情况**，例如，用户表的用户名为空，可能出现没有用户名的情况，导致数据不完整

2. **查询性能**

   把字段设置为NOT NUll，可以提高查询的效率，**数据库在执行查询的时候，不需要额外的去处理空值的情况**，可以更加快速去定位符合条件的数据行

3. **开发的友好性**

   在应用程序的开发中，**如果字段被设置为NOT NULL，就可以减少对空值的额外处理逻辑**，开发人员可以更加简洁和清晰的去编写代码，不需要考虑空值情况的特殊处理

4. **数据一致约束**

   通过把字段设置为NOT NULL，可以在数据库层面强制实施数据一致性的约束，这样可以避免应用程序层面忽略或者错误的处理空值情况，减少了数据质量问题的一个可能性，例如，如果某个字段表示用户的姓名，当该字段允许为空时，有些应用程序可能会在显示用户信息时使用默认值，而其他应用程序可能会显示一个空白。这种不一致会给用户带来困惑，并且会导致数据的混乱。



## 事务

### 28.什么是数据库事务

- 从一种一致性状态变到另一种一致性状态
- 事务是逻辑上的一种操作，要么都执行，要么都不执行

### 29.介绍一下事务具有的四个特征（特性）✔

- 原子性：要么都做，要么都不做
- **一致性**
- 隔离性：并发执行的各个事务之间不能互相干扰
- 持久性

> A向B转账500，转账成功，A扣除500元，B增加500元，
>
> 原子操作体现在要么都成功，要么都失败 
>
> 在转账的过程中，数据要一致，A扣除了500，B必须增加500 
>
> 在转账的过程中，隔离性体现在A向B转账，不能受其他事务干扰 
>
> 在转账的过程中，持久性体现在事务提交后，要把数据持久化（可以说是落盘操作）

### 30.说一下MySQL的四种隔离级别✔

- 读未提交（Read Uncommitted）		有脏读、不可重复读、幻读问题
- 读已提交（Read Committed）		有不可重复读、幻读问题
- 可重复读（Repeatable Read）		**默认事务隔离级别**，有幻读问题（新增+删除）
- 可串行化（Serializable）		可以解决以上这几种问题 ，但由于让是事务串行执行的，性能比较低

### 31.什么是脏读、幻读、不可重复读（并发事务带来哪些问题）✔

- 脏读是一个事务回滚影响另外一个事务

  脏读是指一个事务读取了另一个事务未提交的数据。换句话说，如果事务A读取了事务B尚未提交的数据，而事务B最终回滚了，那么事务A读取的数据就是脏数据。脏读主要发生在并发场景下，可能会引发数据一致性的问题。

- 幻读侧重于新增或删除（多了或少了行）

- 不可重复读侧重于修改

> 第一是脏读， 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 
>
> 第二是不可重复读：比如在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。 这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 
>
> 第三是幻读（Phantom read）：幻读与不可重复读类似。它发生在一个事务 （T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

### 32.事务的实现原理

- 事务是基于重做日志文件（redolog）和回滚日志（undolog）实现的
- 每提交一个事务必须先将该事务的所有日志写入到redolog日志中进行持久化，保证事务的原子性和持久性
- 每当有修改事务时，会产生undolog，如需回滚，根据undolog的方向语句进行逻辑操作，实现数据库的一致性

1. mysql是由mvcc实现的事务控制
2. MVCC 的实现依赖于：隐藏字段、Read View、undo log
3. 在不同的事务隔离级别下通过设置readview内容，控制了哪些数据可见于不可见

### 33.MySQL事务日志介绍下（undo log和redo log的区别）✔

InnoDB事务日志包括redolog和undolog

- `undolog`指事务开始之前，在操作任何数据之前，首先将需要操作的数据备份到一个地方。

  undo log 用来回滚行记录到某个版本。事务未提交之前，Undo 保存了未提交之前的版本数据，Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读。是为了实现事务的原子性而出现的产物,在 MySQL innodb 存储引擎中用来实现多版本并发控制。

- `redolog`指事务中操作的任何数据，将最新的数据备份到一个地方。

  redo log 不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入 redo 中。具体的落盘策略可以进行配置 。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启 MySQL 服务的时候，根据 redo log 进行重做，从而达到事务的未入磁盘数据进行持久化这一特性。RedoLog 是为了实现事务的持久性而出现的产物。

- 事务日志的目的：实例或者介质失败，事务日志文件就能派上用场

> 其中redo log日志记录的是数据页的物理变化，服务宕机可用来同步数据，
>
> 而undo log 不同，它主要记录的是逻辑日志，当事务回滚时，通过逆操作恢复原来的数据，比如我们删除一条数据的时候，就会在 undo log日志文件中新增一条delete语句，如果发生回滚就执行逆操作； 
>
> redo log保证了事务的持久性，undo log保证了事务的原子性和一致

### 34.什么是MySQL的binlog

- MySQL的`binlog`是记录所有数据库表结构变更以及表数据修改的二进制日志。`binlog`不会记录`select`和`show`这类操作，因为这类操作对数据本身并没有修改

### binlog和redolog有什么区别✔

binlog和redolog都是MySQL里面**用来记录数据库变更操作的日志**，其中binlog主要用来做**数据备份、数据恢复、数据同步**，而redolog主要是在MySQL数据库事务的ACID特性里面，用来保证数据的持久化特性，数据库奔溃时，可以通过redolog来恢复未完成的数据，保证数据的完整性，还可以通过合理的配置redolog的大小和数量优化MySQL性能

**区别**

1. 使用场景不同

   binlog主要做**数据备份，数据恢复，以及主从集群的数据同步**

   redolog主要用来实现**MySQL数据库的事务恢复，保证事务的ACID特性**，当数据库出现奔溃时，Redlog可以把未提交的事务回滚，把已提交的事务进行持久化

2. 记录信息不同

   binlog是记录数据库的逻辑变化，三种日志格式statement、row、mixed

   redolog记录的是物理的变化，数据页的变化的结果

3. 记录的时机不同

   binlog是在执行SQL语句的时候，在主线程生成逻辑变化，写入到磁盘里面，**是语句级别的记录方式**

   redolog是在InnoDB存储引擎层面的操作，它是在MySQL后台线程中去生成，并写入磁盘中，**是事务级别的记录方式**，一个事务被操作完后才会写入redolog中

### 35.在事务中可以混合使用存储引擎吗

- 尽量不要在同一个事务中使用多种存储引擎，MySQL服务器层不管理事务，事务是由下层存储引擎实现的。
- 正常提交的情况是不会有什么问题的，**但如果该事务需要回滚，非事务型的表上的变更就无法撤销，这会导致数据库处于不一致的状态**，这种情况很难修复，事务的最终结果将无法确定，所有选择合适的存储引擎非常重要

### 36.MySQL中是如何实现事务隔离的

- 读未提交、串行化基本上是不需要考虑隔离级别的，前者不加锁限制，后者相当于单线程执行，效率太差
- 可重复读级别解决了幻读问题，通过行锁和间隙锁的组合`Next-key`锁实现的

### 37.什么是MVCC✔

多版本并发控制，是通过保存数据在某个时间点的快照来实现的。它的出现，主要是为了解决读写不冲突的问题，让我们MySQL在进行数据更改的时候，依然可以进行无锁去读。

**多版本**

在MySQL锁当中，无论是独占锁还是共享锁，**在修改数据的时候都是不可读不可写的，而在MySQL大多数场景中，是以读为主，如果每一次修改都阻塞我们去读，那么性能就不会很好，为了解决这个问题，就要让读和写发生在不同的数据版本**，不要让他们读同一份数据就可以了，于是就产生了undo log日志，undo log日志会在更新语句之前将原有的数据记录为历史版本，将最新的数据记录为当前版本，此时会产生两种读操作，一种叫当前读，一种叫快照读，快照读其实读的是历史版本，而当前读读的是最新版本。当前版本和各项历史版本通过一个隐藏字段叫roll point来进行互相的连接，这就是MVCC中的多版本的含义

**并发控制**

现在最大的问题就是**当多个事务同时产生需要访问相同数据的时候，应该如何选择与之匹配的版本**，这就叫版本控制。

MySQL通常是通过事务ID来进行具体的版本选择，MySQL会为每一个事务分配一个具体的事务ID，这个事务ID由一个全局的递增的变量来进行控制，每一次修改数据，都会将修改这个数据的事务ID存入一个隐藏字段叫txid当中，于是每一个版本的数据都会多了一个字段叫事务ID，我们可以根据这个事务ID进行版本选择，在有大量并发事务产生的时候，会产生很多是事务ID，这些有的事务已经被提交，有的事务是尚未提交正在运行的，在众多的事务当中，选择一个合适的版本，并不是一个容易的事，readview叫读视图或读快照，一个readview相当于Java中的一个类，里边的数据当成成员变量理解就可以，这些成员变量包含以下内容：1.当前事务id，2.预分配的事务ID，就是下一次分配事务的时候的那个ID，3.正在运行尚未提交的的ID所组成的一个数组这三个部分。

当开启一个事务，并进行select操作的时候，就会生成一个读视图，根据读视图来选择数据版本的方式如下：它会从当前数据开始，沿着版本链逐个和读视图进行事务ID对比，如果当前最新的数据和当前事务ID一样，直接返回最新的版本就可以了，说明没有其他事务在操作这个数据，但如果发现当前数据的事务ID和我们当前事务ID不一致，那就要判断当前数据的这个事务ID在不在这个未提交事务ID的列表当中，这个在readview中也是有保存的，如果不在，说明这个事务已经被提交，这个数据也是可以被读取的，如果在，就说明当前有正在运行的事务，正在修改这个数据，那我们就不要去读这个数据，要沿着版本链，继续找下一条可用的数据，通过对历史版本的回溯对比，我们总能找到一条，适合当前事务的数据进行读取，这就是数据版本的选择过程。

对rc（读已提交）的事务隔离级别，存在不可重复读问题，在RC级别，每一次select语句都会产生一个新的读视图，所以呢每次读取可能会产生不一样的数据，而在RR（可重复读）的隔离级别下，通常第一次select语句会产生一个读视图，在当前事务中，以后每次其他select语句都复用第一次产生的readview，这样就可以保证在一个事务当中，每一次进行select都可以得到相同的数据的版本，这样就解决了不可重复读的问题，串行化相当于禁用了历史版本，每一次读取或修改必须使用当前版本，这样的话性能很差

### 38.MVCC的实现原理（事务中的隔离性是如何保证的呢）✔

- `row id`：隐藏的自增ID
- 事务id：记录最后一次修改该记录的事务ID
- 回滚指针：指向这条记录的上一个版本

InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本，这个历史版本存放在 undo log 中。如果要执行更新操作，会将原记录放入 undo log 中，并通过隐藏的回滚指针指向 undo log 中的原记录。其它事务此时需要查询时，就是查询 undo log 中这行数据的最后一个历史版本。

MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性

> 事务的隔离性是由锁和mvcc实现的。 其中mvcc的意思是多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突，它的底层实现主要是分为了三个部分，第一个是隐藏字段， 第二个是undo log日志，第三个是readView读视图 
>
> 隐藏字段是指：在mysql中给每个表都设置了隐藏字段，有一个是trx_id(事务id)，记录每一次操作的事务id，是自增的；另一个字段是roll_pointer(回滚指针)，指向上一个版本的事务版本记录地址
>
> undo log主要的作用是记录回滚日志，存储老版本数据，在内部会形成一个 版本链，在多个事务并行操作某一行记录，记录不同事务修改数据的版本， 通过roll_pointer指针形成一个链表 
>
> readView解决的是一个事务查询选择版本的问题，在内部定义了一些匹配规则和当前的一些事务id判断该访问那个版本的数据，不同的隔离级别快照读是不一样的，最终的访问的结果不一样。如果是rc隔离级别，每一次执行快照读时生成ReadView，如果是rr隔离级别仅在事务中第一次执行快照读时生成ReadView，后续复用

### InnoDB如何解决幻读✔

幻读是在同一个事务中,前两次查询相同的范围时,得到的结果不一致。（**范围查询**）

InnoDB中引入了MVCC和LBCC两种机制来解决幻读，其中LBCC用到了临键锁、间隙锁和行锁。举例如下：

```sql
select * from user where id = 1 for update;				#01-SQL

select * from user where id > 4 and id < 7 for update;	#02-SQL
insert into user (id,name) values(5,"xiaobai")			#03-SQL

select * from user where id > 4 for update;				#04-SQL

```

存在B+Tree索引，有四个索引元素，分别是1、4、7、10，通过主键索引查询一条记录（**01-sql**），并且对这条记录通过for update 加锁的时候，这时会产生一个record lock，也就是记录锁或者行锁，锁定id=1的这个索引，被锁定的记录，在锁释放之前，其他事务是无法对这条记录做任务操作的。刚提到幻读的定义，也就是说InnoDB要引擎要解决幻读问题，必须要保证一个点，就是如果一个事务通过这样一条语句（**02-SQL**）进行锁定的时候，另外一个事务在执行这样一条insert语句（**03-SQL**），需要被阻塞，直到前面获得锁的事务释放掉，所有在InnoDB中设计了一种间隙锁，它的主要功能是锁定一定范围内的索引记录，当对查询范围id>4 and id<7 加锁的时候，会针对B+Tree中的4和7这个开区间范围的索引加间隙锁，意味着在这种情况下，其他事务对这个区间的数据进行插入、更新、删除的时候都会被锁住，但是还有另外一种情况，比如说像这样（**04-SQL**）这条查询语句是针对id>4 这个条件加锁，那么它需要锁定多个索引区间，所以在这种情况下，InnoDB引入了`next-key Lock`机制，`next-key Lock`相当于间隙锁加记录锁的合集，记录锁锁定的是存在的记录行，间隙锁锁定是记录行直接的间隙，而`next-key Lock`锁住的是两者之和，每个数据行上的非唯一索引列上，都会存在一个`next-key Lock`的时候，会锁住一段左开右闭区间的数据，因此当id > 4 ，这样一种范围查询加锁的时候，会加`next-key Lock`，锁定的区间范围是`(4,7] (7,10](10,+无穷]`这样的，间隙锁和`next-key Lock`的区别在于加锁的范围，**间隙锁只锁定两个索引之间的引用间隙，而`next-key lock`会锁定多个索引区间，包含记录锁和间隙锁**，当我们使用了范围查询，不仅仅命中了`record lock`，还包含了Gap间隙，在这种情况下，我们使用的就是临键锁，它是MySQL里面默认的行锁算法。

虽然lnnoDB中通过间隙锁的方式解决了幻读问题,但是加锁之后一定会影响到并发性能,因此如果对性能要求较高的业务场景中可以把隔离级别设置成RC，这个级别中不存在间隙锁。

## 锁

### 39.为什么要加锁

- 保证多用户环境下保证数据库完整性和一致性

### 40.按照锁的粒度分数据库锁有哪些

- 行级锁（`InnoDB`）对当前操作的行加锁
- 表级锁（`MyISAM`）对当前操作的整张表加锁
- 页级锁（`BDB`） 锁定粒度介于行级锁和表级锁中间的一种锁  

### 41.从锁的类别上分MySQL那些锁呢

- 共享锁（读锁，与其他共享锁不互斥，与排他锁互斥）
- 排他锁（写锁，与其他排他锁、共享锁都互斥）

### 42.数据库的乐观锁和悲观锁是什么？怎么实现的✔

乐观和悲观说的是对于锁的处理方式

- 悲观锁（多写场景）
  - 假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。**在查询完数据的时候就把事务锁起来**，直到提交事务。实现方式：使用数据库中的锁机制。
- 乐观锁（多读场景）
  - 假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。**在修改数据的时候把事务锁起来**，通过version的方式来进行锁定。

### 43.InnoDB引擎的行锁是怎么实现的

- 基于索引来完成行锁

### 44.什么是死锁？怎么解决

- 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象
- 解决方法
  - 尽量约定相同的顺序访问表
  - 尽可能做到一次锁定所需要的所有资源
  - 升级锁定颗粒度

### 45.隔离级别与锁的关系

- `readuncommitted`
- `readcommitted`加共享锁
- `repeatableread`加共享锁
- `Serializable`

### 46.优化锁的方面的意见

- 使用较低的隔离级别
- 设计索引，使用索引去访问数据
- 选择合理的事务大小
- 不同程序访问一张表的时候，尽量约定相同的顺序访问表
- 。。。

## 分库分表

### 47.为什么要分库分表

- 分库：将一个库的数据拆分到多个库中吗，访问的时候就访问一个库好了
  - 并发量特别大的时候，单库可能不足以支撑
- 分表：把一个表的数据放到多个表中，然后查询的时候你就查一个表
  - 在一张表中数据量特别大的时候，数据库的压力也会相对增大，SQL执行的速度也会有一定的影响，为了提高数据库的性能，就要进行分表操作，将一个表的数据放到多个表中，对单个表进行相应的查询，提高整体性能。

### 48.用过哪些分库分表中间件？不同的分库分表中间件都有什么优点

### 49.如何对数据库进行垂直拆分或水平拆分的✔

- 垂直拆分
  - 把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样
- 水平拆分
  - 把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都是一样的

### 使用过水平分库吗✔

嗯，这个是使用过的，我们当时的业务是(xxx)，一开始，我们也是单库，后来这个业务逐渐发展，业务量上来的很迅速，其中(xx)表已经存放了超过 1000万的数据，我们做了很多优化也不好使，性能依然很慢，所以当时就使用了水平分库。 

我们一开始先做了3台服务器对应了3个数据库，由于库多了，需要分片，我们当时采用的mycat来作为数据库的中间件。数据都是按照id（自增）取模的方式来存取的。 

当然一开始的时候，那些旧数据，我们做了一些清洗的工作，我们也是按照 id取模规则分别存储到了各个数据库中，好处就是可以让各个数据库分摊存储和读取的压力，解决了我们当时性能的问题

### 你们项目用过MySQL的分库分表吗

因为我们都是微服务开发，每个微服务对应了一个数据库，是根据业务进行拆分的，这个其实就是垂直拆分。



## 读写分离、中从同步（复制）

### 50.什么是MySQL主从同步

- 主从同步使得数据可以从一个数据库服务器复制到其他服务器上

### 51.MySQL主从同步的目的？为什么要做主从同步

- 读写分离，提高数据库性能
- 数据备份，提高数据安全

### 52.如何实现MySQL的读写分离

- 主从复制架构（主写从读）

### 53.MySQL主从复制流程和原理(MySQL主从同步原理)✔

- 主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的`binlog`中
- 从：io线程——在使用startslave之后，负责从master上拉取binlog内容，放进自己的**relaylog**中
- 从：SQL执行线程——执行relaylog中的语句

> MySQL主从复制的核心就是二进制日志(DDL（数据定义语言）语句 和 DML（数据操纵语言）语句)，它的步骤是这样的： 
>
> 第一：主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中。 
>
> 第二：从库读取主库的二进制日志文件 Binlog ，写入到从库的中继日志 Relay Log 。 
>
> 第三：从库重做中继日志中的事件，将改变反映它自己的数据

### 54.MySQL主从同步延时问题如何解决✔

- 半同步复制：解决主库数据库丢失问题
- 并行复制：解决主从同步延时问题
  - 从库开启多个线程，**并行读取relay log 中不同库的日志**，然后并行重放不同库的日志，这是库级别的并行

1. 设计一主多从的方式来分担从库的压力，减少主从同步延迟的一个问题
2. 如果对数据一致性要求较高，那么在从库存在延迟的情况下，可以强制走主库查询数据
3. 可以在从库上执行show slave status命令，获取seconds_behind_master字段的延迟时间，然后通过sleep阻塞等待固定时间后再次查询
4. 可以通过并行复制解决从库复制延迟的问题

主从复制的场景无法避免同步延迟这样一个情况，如果一定要用强一致方案，应该考虑到其他能够实现实时数据一致性的一个技术方案



## 优化

### 55.如何定位及优化SQL语句的性能问题(SQL语句执行很慢, 如何分析)✔

- `explain`

可以采用EXPLAIN 或者 DESC命令获取 MySQL 如何执行 SELECT 语句的信息

```sql
- 直接在select语句之前加上关键字 explain / desc 
EXPLAIN   SELECT   字段列表   FROM   表名   WHERE  条件 ;
```

![image-20230608100903292](https://gitee.com/tjlxy/img/raw/master/image-20230608100903292.png)

### 56.大数据表查询，怎么优化

- 优化shemale、SQL+索引
- 加缓存，redis
- 主从复制、读写分离
- 垂直拆分
- 水平拆分

### 57.超大分页怎么处理✔

- 嗯，超大分页一般都是在数据量比较大时，我们使用了limit分页查询，并且需要对数据进行排序，这个时候效率就很低，我们可以采用覆盖索引和子查询来解决 
- 先分页查询数据的id字段，确定了id之后，再用子查询来过滤，只查询这个 id列表中的数据就可以了 
- 因为查询id的时候，走的覆盖索引，所以效率可以提升很多

> ```sql
> select * from tb_sku limit 9000000,10;
> #当在进行分页查询时，如果执行 limit 9000000,10 ，此时需要MySQL排序前9000010 记录，仅仅返回 9000000 - 9000010 的记录，其他记录丢弃，查询排序的代价非常大 。
> 
> #优化思路: 一般分页查询时，通过创建 覆盖索引 能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化
> select *
> from tb_sku t,
> 	(select id from tb_sku order by id limit 9000000,10) a
> where t.id = a.id;
> ```
>
> 

### 58.统计过慢查询吗？对慢查询都怎么优化过✔

- 分析语句
- 分析语句的执行计划
- 数据量太大，可以分表

### 如何定位慢查询✔

方案一：开源工具

- 调试工具：Arthas 

- 运维工具：Prometheus 、Skywalking

> 我们当时做压测的时候有的接口非常的慢，接口的响应时间超过了2秒以上，因为我们当时的系统部署了运维的监控系统Skywalking ，在展示的报表中可以看到是哪一个接口比较慢，并且可以分析这个接口哪部分比较慢，这里可以看到SQL的具体的执行时间，所以可以定位是哪个sql出了问题。

方案二：MySQL自带慢查询日志

慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有SQL语句的日志

如果要开启慢查询日志，需要在MySQL的配置文件（/etc/my.cnf）中配置如下信息：

```shell
# 开启MySQL慢日志查询开关
slow_query_log=1
# 设置慢日志的时间为2秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询日志
long_query_time=2

```

配置完毕之后，通过以下指令重新启动MySQL服务器进行测试，查看慢日志文件中记录的信息 /var/lib/mysql/localhost-slow.log。

![image-20230608100542705](https://gitee.com/tjlxy/img/raw/master/image-20230608100542705.png)

> 如果，项目中没有这种运维的监控系统，其实在MySQL中也提供了慢日志查询的功能，可以在MySQL的系统配置文件中开启这个慢日志的功能，并且也可以设置SQL执行超过多少时间来记录到一个日志文件中，我记得上一个项目配置的是2秒，只要SQL执行的时间超过了2秒就会记录到日志文件中，我们就可以在日志文件找到执行比较慢的SQL了。

### 59.如何优化查询过程中的数据访问

- 访问数据太多导致查询性能下降
- 确定应用程序是否在检索大量超过需要的数据，可能是太多行或列
- 确认MySQL服务器是否在分析大量不必要的数据行
- 查询不需要的数据。解决办法：使用limit解决
- 多表关联返回全部列。解决办法：指定列名
- 总是返回全部列。解决办法：避免使用SELECT *
- 重复查询相同的数据。解决办法：可以缓存数据，下次直接读取缓存
- 是否在扫描额外的记录。解决办法： 使用explain进行分析，如果发现查询需要扫描大量的数据，但只返回少数的行，可以通过如下技巧去优化： 使用索引覆盖扫描，把所有的列都放到索引中，这样存储引擎不需要回表获取对应行就可以返回结果。
- 改变数据库和表的结构，修改数据表范式
- 重写SQL语句，让优化器可以以更优的方式执行查询。

### 60.如何优化关联查询

- 确定ON或者USING子句中是否有索引。
- 确保GROUP BY和ORDER BY只有一个表中的列，这样MySQL才有可能使用索引。

### 61.数据库结构优化

- 将字段很多的表分解成多个表
- 增加中间表
- 增加冗余字段

### 62.MySQL数据库CPU飙升到500%的话他怎么处理

- `top`命令查看占用大的进程
- 判断是否为MySQLd占用导致
  - 不是，找出相关占用高的进程，进行相关处理
  - 是
    - `show processlist`命令查看`session`情况，调整相关SQL语句，重写执行
    - 可能是突然之间有大量的`session`连进来导致CPU飙升，做出相应调整

### 63.大表怎么优化

- 限定数据的范围
- 读/写分离
- **缓存**
- **分库分表**

### SQL优化经验✔

- 表的设计优化
- 索引优化（参考优化创建原则和索引失效）
- SQL语句优化
- 主从复制、读写分离
- 分库分表 （参考上述内容）

> **表的优化：**
>
> 建表的时候、使用索引、sql语句的编写、主从复制，读写分离，还有一个是如果量比较大的话，可以考虑分库分表
>
> 在定义字段的时候需要结合字段的内容来选择合适的类型，如果是数值的话，像tinyint、int 、bigint这些类型，要根据实际情况选择。如果是字符串类型，也是结合存储的内容来选择char和varchar或者text类型
>
> **索引优化**（参考优化创建原则和索引失效）
>
> **SQL语句优化：**
>
> 如SELECT语句务必指明字段名称，不要直接使用select * ，还有就是要注意SQL语句避免造成索引失效的写法；如果是聚合查询，尽量用union all代替union ，union会多一次过滤，效率比较低； 如果是表关联的话，尽量使用innerjoin ，不要使用用left join right join，如必须使用 一定要以小表为驱动



### 优化数据库的方法有哪些

1. 硬件 主要在存储层优化
2. 网络
3. 操作系统调优
4. 表结构设计优化：字段类型。。。
5. sql优化
6. 减少函数使用
7. 索引优化
8. 大字段及全文检索优化
9. 连接池优化
10. 事务优化
11. 数据库集群化
12. 加入缓存
13. 冷热存储
14. 分库分表



### limit 500000,10和limit 10速度一样快吗

1. **数据量**

   如果数据库中的数据量很小，那么两个查询的速度可能相差不大，但是如果数据库中的数据量非常大，那么`limit 500000,10` 会跳过大量的数据行才能返回结果，而`limt 10`则不需要跳过这些数据行

2. **索引**

   如果表中有合适的索引，那么使用`limit 500000,10`的时候，数据库可以通过索引来直接定位到指定的行号，并返回结果，而对于`limit 10`数据库只需要返回前10行数据即可，

不论什么因素，`limit 500000,10`的查询速度肯定比`limit 10`要慢一些，而随着数据量的增加，前者的查询速度会更慢，因此可以从两个方面来优化：

1. **从SQL语句层面优化**，假设存在主键id，可以先使用子查询的结果作为过滤条件，从第500000行的主键值开始获取10行数据，这样可以跳过大量的数据行，提高查询效率
2. **从业务层面优化**，正常情况下很少会出现翻50w页查询一个数据，这种问题本身就会存在问题，如果涉及到大量数据的翻页查询，可以尝试做**冷热数据的分离**，减少热数据的查询量，或者**针对运营要用的数据做一次分析**，形成固化表以后展示出来



### 使用innodb引擎，mysql索引的最左前缀如何优化orderby语句

1. 首先要对sql进行分析检查必要的查询字段，过滤字段，排序字段是否按顺序创建好了索引
2. 如果查询字段不再索引中可能会产生回表操作会导致filesort，降低性能
3. 一定要有过滤字段不然不能使用索引
4. 排序字段和索引顺序不一致会导致filesort，降低性能
5. 多个字段排序时如果方向不一致也会导致filesort，降低性能
6. 使用explain观察查询类型和索引利用情况
7. 尽可能减少不必要的filesort



## 其他

**典型的JDBC程序按(dbecfa)顺序编写( 排序)**

A.释放资源

B.获得与数据库的物理连接

C.执行SQL命令

D.注册JDBC Driver

E.创建不同类型的statement

F.如果有结果集，处理结果集

**下列语句哪一个正确(B)**

A.Java 程序经编译后会产生 machine code

> 在CPU上执行的指令集，0101...

B.Java 程序经编译后会产生 byte code

> 字节码

C.Java 程序经编译后会产生 DLL

> 动态链接库

D.以上都不正确
