(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{324:function(a,v,_){"use strict";_.r(v);var t=_(1),r=Object(t.a)({},(function(){var a=this,v=a._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[v("h1",{attrs:{id:"消息中间件mq"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消息中间件mq"}},[a._v("#")]),a._v(" 消息中间件MQ")]),a._v(" "),v("h2",{attrs:{id:"基础"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础"}},[a._v("#")]),a._v(" 基础")]),a._v(" "),v("h3",{attrs:{id:"为什么要用mq✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么要用mq✔"}},[a._v("#")]),a._v(" 为什么要用MQ✔")]),a._v(" "),v("p",[a._v("使用MQ的场景很多，主要有三个：解耦、异步、削峰。")]),a._v(" "),v("ul",[v("li",[v("p",[a._v("1、解耦：假设现在，日志不光要"),v("strong",[a._v("插入到数据库")]),a._v("里，还要"),v("strong",[a._v("在硬盘中增加文件类型的日志")]),a._v("，同时，一些"),v("strong",[a._v("关键日志还要通过邮件的方式发送给指定的人")]),a._v("。那么，如果按照原来的逻辑，A可能就需要在原来的代码上做扩展，除了B服务，还要加上日志文件的存储和日志邮件的发送。但是，如果你使用了MQ，那么，A服务是不需要做更改的，"),v("strong",[a._v("它还是将消息放到MQ中即可，其它的服务，无论是原来的B服务还是新增的日志文件存储服务或日志邮件发送服务，都直接从MQ中获取消息并处理即可")]),a._v("。这就是解耦，它的好处是提高系统灵活性，扩展性。")])]),a._v(" "),v("li",[v("p",[a._v("2、异步：可以将一些非核心流程，如日志，短信，邮件等，通过MQ的方式异步去处理。这样做的好处是"),v("strong",[a._v("缩短主流程的响应时间")]),a._v("，提升用户体验。")])]),a._v(" "),v("li",[v("p",[a._v("3、削峰：MQ的本质就是业务的排队。所以，面对突然到来的高并发，MQ也可以不用慌忙，先排好队，不要着急，一个一个来。削峰的好处就是避免高并发压垮系统的关键组件，如某个核心服务或数据库等。")]),a._v(" "),v("p",[a._v("举个例子，假设订单系统最多能处理一万次订单，但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，"),v("strong",[a._v("这时有些用户可能在下单十几秒后才能收到下单成功的操作")]),a._v("，但是比不能下单的体验要好。")])])]),a._v(" "),v("blockquote",[v("p",[v("strong",[a._v("解耦")])]),a._v(" "),v("p",[a._v("场景：A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃......")]),a._v(" "),v("p",[a._v("在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！")]),a._v(" "),v("p",[a._v("如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。")]),a._v(" "),v("p",[a._v("总结：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。")]),a._v(" "),v("p",[v("img",{attrs:{src:"https://gitee.com/tjlxy/img/raw/master/image-20231011093402549.png",alt:"image-20231011093402549"}})]),a._v(" "),v("p",[v("strong",[a._v("异步")])]),a._v(" "),v("p",[a._v("场景：A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。")]),a._v(" "),v("p",[a._v("一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。")]),a._v(" "),v("p",[a._v("如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了。")]),a._v(" "),v("p",[v("img",{attrs:{src:"https://gitee.com/tjlxy/img/raw/master/image-20231007204210099.png",alt:"image-20231007204210099"}})]),a._v(" "),v("p",[v("strong",[a._v("肖峰")])]),a._v(" "),v("p",[a._v("场景：每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。")]),a._v(" "),v("p",[a._v("使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。")]),a._v(" "),v("p",[a._v("这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。")]),a._v(" "),v("p",[v("img",{attrs:{src:"https://gitee.com/tjlxy/img/raw/master/image-20231007204246850.png",alt:"image-20231007204246850"}})]),a._v(" "),v("p",[v("strong",[a._v("缓冲")])]),a._v(" "),v("p",[v("img",{attrs:{src:"https://gitee.com/tjlxy/img/raw/master/image-20231007204308164.png",alt:"image-20231007204308164"}})])]),a._v(" "),v("h3",{attrs:{id:"消息队列的缺点✔❕"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消息队列的缺点✔❕"}},[a._v("#")]),a._v(" 消息队列的缺点✔❕")]),a._v(" "),v("p",[a._v("1、 系统可用性降低")]),a._v(" "),v("p",[a._v("系统引入的外部依赖越多，越容易挂掉。")]),a._v(" "),v("p",[a._v("2、 系统复杂度提高")]),a._v(" "),v("p",[a._v("加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，复杂性增大。")]),a._v(" "),v("p",[a._v("3、 一致性问题")]),a._v(" "),v("p",[a._v("A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，这就数据不一致了。")]),a._v(" "),v("h3",{attrs:{id:"kafka、activemq、rabbitmq、rocketmq-有什么优缺点✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka、activemq、rabbitmq、rocketmq-有什么优缺点✔"}},[a._v("#")]),a._v(" Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点✔")]),a._v(" "),v("p",[v("img",{attrs:{src:"https://gitee.com/tjlxy/img/raw/master/image-20231113090804615.png",alt:"image-20231113090804615"}})]),a._v(" "),v("p",[a._v("Kafka：追求高吞吐量，适合产生大量数据的互联网服务的数据收集业务")]),a._v(" "),v("p",[a._v("RocketMQ：可靠性要求很高的金融互联网领域,稳定性高，经历了多次阿里双11考验")]),a._v(" "),v("p",[a._v("RabbitMQ：性能较好，社区活跃度高，数据量没有那么大，优先选择功能比较完备的RabbitMQ")]),a._v(" "),v("ul",[v("li",[a._v("中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；")]),a._v(" "),v("li",[a._v("大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。")]),a._v(" "),v("li",[a._v("大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，几乎是全世界这个领域的事实性规范。")])]),a._v(" "),v("blockquote",[v("p",[v("strong",[a._v("Kafka：")])]),a._v(" "),v("p",[a._v("优点：高吞吐量、低延迟、可持久化、可扩展性强。Kafka适用于大规模的数据流式处理和实时数据管道。")]),a._v(" "),v("p",[a._v("缺点：复杂性较高，学习曲线陡峭。Kafka的配置和管理相对复杂，需要一定的技术专业知识。")]),a._v(" "),v("p",[v("strong",[a._v("ActiveMQ")]),a._v("：")]),a._v(" "),v("p",[a._v("优点：功能丰富、易于使用、社区活跃。ActiveMQ支持多种通信协议，提供了广泛的特性和灵活的集成方式。")]),a._v(" "),v("p",[a._v("缺点："),v("strong",[a._v("可靠性相对较低")]),a._v("。在处理大量消息或高并发情况下，ActiveMQ可能会出现性能问题。")]),a._v(" "),v("p",[v("strong",[a._v("RabbitMQ")]),a._v("：")]),a._v(" "),v("p",[a._v("优点："),v("strong",[a._v("可靠性高")]),a._v("、灵活性好、易于使用。RabbitMQ的设计注重可靠性，支持多种消息传递模式和灵活的路由规则。")]),a._v(" "),v("p",[a._v("缺点：性能相对较低。在需要处理大量消息的高吞吐量场景下，RabbitMQ可能会出现性能瓶颈。")]),a._v(" "),v("p",[v("strong",[a._v("RocketMQ")]),a._v("：")]),a._v(" "),v("p",[a._v("优点：高可靠性、低延迟、扩展性好。RocketMQ在分布式事务、高可用性和水平扩展方面表现出色，适用于大规模的分布式架构。")]),a._v(" "),v("p",[a._v("缺点：对运维要求较高。RocketMQ的部署和维护相对复杂，需要一定的运维经验和工作量。")]),a._v(" "),v("p",[a._v("需要注意的是，选择消息中间件系统时应根据具体的业务需求和场景来考虑，没有绝对的优劣之分，最适合的系统取决于实际情况。")])]),a._v(" "),v("h2",{attrs:{id:"rabbitmq"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#rabbitmq"}},[a._v("#")]),a._v(" RabbitMQ")]),a._v(" "),v("h3",{attrs:{id:"rabbitmq-如何保证消息不丢失✔❕"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#rabbitmq-如何保证消息不丢失✔❕"}},[a._v("#")]),a._v(" RabbitMQ-如何保证消息不丢失✔❕")]),a._v(" "),v("p",[a._v("当MYSQL和Redis的数据双写一致性就是采用RabbitMQ实现同步的，这里面就要求了消息的高可用性，我们要保证消息的不丢失。主要从三个层面考虑")]),a._v(" "),v("p",[a._v("第一个是"),v("strong",[a._v("开启生产者确认机制，确保生产者的消息能到达队列")]),a._v("，如果报错可以先记录到日志中，再去修复数据")]),a._v(" "),v("p",[a._v("第二个是"),v("strong",[a._v("开启持久化功能")]),a._v("，"),v("strong",[a._v("确保消息未消费前在队列中不会丢失")]),a._v("，其中的交换机、队列、和消息都要做持久化")]),a._v(" "),v("p",[a._v("第三个是"),v("strong",[a._v("开启消费者确认机制为auto")]),a._v("，"),v("strong",[a._v("由spring确认消息处理成功后完成 ack")]),a._v("，当然也需要设置一定的重试次数，我们当时设置了3次，如果重试3次还没有收到消息，就将失败后的消息投递到异常交换机，交由人工处理")]),a._v(" "),v("h3",{attrs:{id:"rabbitmq消息的重复消费问题如何解决的✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#rabbitmq消息的重复消费问题如何解决的✔"}},[a._v("#")]),a._v(" RabbitMQ消息的重复消费问题如何解决的✔")]),a._v(" "),v("p",[a._v("嗯，这个我们还真遇到过，是这样的，我们当时"),v("strong",[a._v("消费者是设置了自动确认机制，当服务还没来得及给MQ确认的时候，服务宕机了，导致服务重启之后，又消费了一次消息")]),a._v("。这样就重复消费了")]),a._v(" "),v("p",[a._v("因为我们当时处理的支付（订单|业务唯一标识），"),v("strong",[a._v("它有一个业务的唯一标识，我们再处理消息时，先到数据库查询一下，这个数据是否存在")]),a._v("，如果不存在，说明没有处理过，这个时候就可以正常处理这个消息了。如果已经存在这个数据了，就说明消息重复消费了，我们就不需要再消费了")]),a._v(" "),v("h4",{attrs:{id:"那你还知道其他的解决方案吗✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#那你还知道其他的解决方案吗✔"}},[a._v("#")]),a._v(" 那你还知道其他的解决方案吗✔")]),a._v(" "),v("p",[a._v("其实这个就是典型的幂等的问题，比如，redis分布式锁、数据库的锁都是可以的")]),a._v(" "),v("h3",{attrs:{id:"rabbitmq中死信交换机-rabbitmq延迟队列有了解过嘛-✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#rabbitmq中死信交换机-rabbitmq延迟队列有了解过嘛-✔"}},[a._v("#")]),a._v(" RabbitMQ中死信交换机（RabbitMQ延迟队列有了解过嘛）✔")]),a._v(" "),v("p",[a._v("我们当时的xx项目有一个xx业务，需要用到延迟队列，其中就是使用 RabbitMQ来实现的。")]),a._v(" "),v("p",[a._v("延迟队列就是用到了死信交换机和TTL（消息存活时间）实现的。")]),a._v(" "),v("p",[a._v("如果消息超时未消费就会变成死信，在RabbitMQ中如果消息成为死信，队列可以绑定一个死信交换机，在死信交换机上可以绑定其他队列，在我们发消息的时候可以按照需求指定TTL的时间，这样就实现了延迟队列的功能了。")]),a._v(" "),v("p",[a._v("我记得RabbitMQ还有一种方式可以实现延迟队列，在RabbitMQ中安装一个死信插件，这样更方便一些，我们只需要在声明交互机的时候，指定这个就是死信交换机，然后在发送消息的时候直接指定超时时间就行了，相对于死信交换机+TTL要省略了一些步骤")]),a._v(" "),v("h3",{attrs:{id:"如果有100万消息堆积在mq-如何解决✔❕"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#如果有100万消息堆积在mq-如何解决✔❕"}},[a._v("#")]),a._v(" 如果有100万消息堆积在MQ , 如何解决✔❕")]),a._v(" "),v("p",[a._v("我在实际的开发中，没遇到过这种情况，不过，如果发生了堆积的问题，解决方案也所有很多的")]),a._v(" "),v("p",[a._v("第一：提高消费者的消费能力 ,可以使用多线程消费任务")]),a._v(" "),v("p",[a._v("第二：增加更多消费者，提高消费速度使用工作队列模式, 设置多个消费者消费同一个队列中的消息")]),a._v(" "),v("p",[a._v("第三：扩大队列容积，提高堆积上限")]),a._v(" "),v("p",[a._v("第四：最后还可以使用RabbitMQ惰性队列，惰性队列的好处主要是")]),a._v(" "),v("p",[a._v("​\t①接收到消息后直接存入磁盘而非内存")]),a._v(" "),v("p",[a._v("​\t②消费者要消费消息时才会从磁盘中读取并加载到内存")]),a._v(" "),v("p",[a._v("​\t③支持数百万条的消息存储")]),a._v(" "),v("h3",{attrs:{id:"rabbitmq的高可用机制有了解过嘛✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#rabbitmq的高可用机制有了解过嘛✔"}},[a._v("#")]),a._v(" RabbitMQ的高可用机制有了解过嘛✔")]),a._v(" "),v("p",[a._v("我们当时项目在生产环境下，使用的集群，当时搭建是镜像模式集群，使用了3台机器。")]),a._v(" "),v("p",[a._v("镜像队列结构是一主多从，所有操作都是主节点完成，然后同步给镜像节点，如果主节点宕机后，镜像节点会替代成新的主节点，不过在主从同步完成前，主节点就已经宕机，可能出现数据丢失")]),a._v(" "),v("h3",{attrs:{id:"那出现丢数据怎么解决呢✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#那出现丢数据怎么解决呢✔"}},[a._v("#")]),a._v(" 那出现丢数据怎么解决呢✔")]),a._v(" "),v("p",[a._v("我们可以采用仲裁队列，与镜像队列一样，都是主从模式，支持主从数据同步，主从同步基于Raft协议，强一致。")]),a._v(" "),v("p",[a._v("并且使用起来也非常简单，不需要额外的配置，在声明队列的时候只要指定这个是仲裁队列即可")]),a._v(" "),v("h3",{attrs:{id:"说说broker服务节点、queue队列、exchange交换器"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#说说broker服务节点、queue队列、exchange交换器"}},[a._v("#")]),a._v(" 说说Broker服务节点、Queue队列、Exchange交换器")]),a._v(" "),v("ul",[v("li",[a._v("Broker可以看做RabbitMQ的服务节点。一般请下一个Broker可以看做一个RabbitMQ服务器。")]),a._v(" "),v("li",[a._v("Queue：RabbitMQ的内部对象，用于存储消息。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。")]),a._v(" "),v("li",[a._v("Exchange：生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃。")])]),a._v(" "),v("h3",{attrs:{id:"rabbitmq中的消息是有顺序的吗"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#rabbitmq中的消息是有顺序的吗"}},[a._v("#")]),a._v(" RabbitMQ中的消息是有顺序的吗")]),a._v(" "),v("p",[a._v("在 RabbitMQ 中，消息通常是无序的。这意味着当多个消息被发送到同一个队列时，并不能保证它们会以相同的顺序被消费。这是因为 RabbitMQ 采用了多种优化和并发处理技术，使得消息可以以并行或异步的方式进行处理。")]),a._v(" "),v("p",[a._v("然而，如果你确实需要保持消息的顺序，RabbitMQ 也提供了一些解决方案。例如，你可以将所有相关消息发送到同一个队列中，并在消费者端进行处理时保持顺序。另外，你还可以利用消息的属性或者特定的消息标识来实现自定义的顺序控制。")]),a._v(" "),v("p",[a._v("此外，RabbitMQ 也支持使用单一消费者来确保消息的顺序性。通过限制每个队列只有一个消费者，你可以保证消息会按照发送的顺序来进行处理。")]),a._v(" "),v("p",[a._v("总的来说，虽然 RabbitMQ 中的消息本身没有固有的顺序，但你可以通过一些方法来实现对消息处理顺序的控制和管理。")]),a._v(" "),v("h2",{attrs:{id:"kafka"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka"}},[a._v("#")]),a._v(" Kafka")]),a._v(" "),v("h3",{attrs:{id:"什么是apache-kafka"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#什么是apache-kafka"}},[a._v("#")]),a._v(" 什么是Apache Kafka")]),a._v(" "),v("p",[v("img",{attrs:{src:"https://gitee.com/tjlxy/img/raw/master/image-20231007204449792.png",alt:"image-20231007204449792"}})]),a._v(" "),v("ul",[v("li",[a._v("由Apache开发的发布订阅消息系统，分布式的、分区的和重复的日志服务。")])]),a._v(" "),v("h3",{attrs:{id:"kafka都有哪些特点✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka都有哪些特点✔"}},[a._v("#")]),a._v(" Kafka都有哪些特点✔")]),a._v(" "),v("p",[v("strong",[a._v("高吞吐量、低延迟")]),a._v("：kafka每秒可以处理⼏⼗万条消息，它的延迟最低只有⼏毫秒，每个topic可以分多个partition, consumer group 对partition进⾏consume操作。")]),a._v(" "),v("p",[v("strong",[a._v("可扩展性")]),a._v("：kafka集群⽀持热扩展")]),a._v(" "),v("p",[v("strong",[a._v("持久性、可靠性")]),a._v("：消息被持久化到本地磁盘，并且⽀持数据备份防⽌数据丢失")]),a._v(" "),v("p",[v("strong",[a._v("容错性")]),a._v("：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）")]),a._v(" "),v("p",[v("strong",[a._v("高并发")]),a._v("：⽀持数千个客户端同时读写")]),a._v(" "),v("h3",{attrs:{id:"kafka-的设计架构✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka-的设计架构✔"}},[a._v("#")]),a._v(" Kafka 的设计架构✔")]),a._v(" "),v("p",[v("img",{attrs:{src:"https://gitee.com/tjlxy/img/raw/master/image-20230728093641551.png",alt:"image-20230728093641551"}})]),a._v(" "),v("ul",[v("li",[a._v("Producer：消息生产者")]),a._v(" "),v("li",[a._v("Consumer：消息消费者")]),a._v(" "),v("li",[a._v("Topic：一个队列，又分为多个分区")]),a._v(" "),v("li",[a._v("Consumer Gropu：一个topic可以有多个Consumer Group")]),a._v(" "),v("li",[a._v("Broker：服务器，一个集群由多个Broker组成，一个Broker可以容纳多个topic")]),a._v(" "),v("li",[a._v("Partition：Partition中每条消息都会分配一个有序id（offset），kafka只能保证一个Partition中的消息的顺序，不能保证一个topic的整体顺序")]),a._v(" "),v("li",[a._v("Offset：存储文件都是按照offset.kafka来命名")])]),a._v(" "),v("p",[v("img",{attrs:{src:"https://gitee.com/tjlxy/img/raw/master/image-20231007204547449.png",alt:"image-20231007204547449"}})]),a._v(" "),v("h3",{attrs:{id:"kafka消息是采用pull模式-还是push模式✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka消息是采用pull模式-还是push模式✔"}},[a._v("#")]),a._v(" Kafka消息是采用Pull模式，还是Push模式✔")]),a._v(" "),v("ul",[v("li",[a._v("Producer向Broker推送消息")]),a._v(" "),v("li",[a._v("Consumer向Broker拉取消息")])]),a._v(" "),v("h3",{attrs:{id:"kafka是如何保证消息不丢失✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka是如何保证消息不丢失✔"}},[a._v("#")]),a._v(" Kafka是如何保证消息不丢失✔")]),a._v(" "),v("p",[a._v("这个保证机制很多，在发送消息到消费者接收消息，在每个阶段都有可能会丢失消息，所以我们解决的话也是从多个方面考虑")]),a._v(" "),v("p",[a._v("第一个是生产者发送消息的时候，可以使用异步回调发送，如果消息发送失败，我们可以通过回调获取失败后的消息信息，可以考虑重试或记录日志， 后边再做补偿都是可以的。同时在生产者这边还可以设置消息重试，有的时候是由于网络抖动的原因导致发送不成功，就可以使用重试机制来解决")]),a._v(" "),v("p",[a._v("第二个在broker中消息有可能会丢失，我们可以通过kafka的复制机制来确保消息不丢失，在生产者发送消息的时候，可以设置一个acks，就是确认机制。我们可以设置参数为all，这样的话，当生产者发送消息到了分区之后， 不仅仅只在leader分区保存确认，在follwer分区也会保存确认，"),v("strong",[a._v("只有当所有的副本都保存确认以后才算是成功发送了消息")]),a._v("，所以，这样设置就很大程度了保证了消息不会在broker丢失")]),a._v(" "),v("p",[a._v("第三个有可能是在消费者端丢失消息，kafka消费消息都是按照offset进行标记消费的，消费者默认是自动按期提交已经消费的偏移量，默认是每隔5s提 交一次，如果出现重平衡的情况，可能会重复消费或丢失数据。我们一般都会禁用掉自动提交偏移量，改为手动提交，当消费成功以后再报告给broker 消费的位置，这样就可以避免消息丢失和重复消费了")]),a._v(" "),v("blockquote",[v("ul",[v("li",[a._v("数据丢失")]),a._v(" "),v("li",[a._v("ack=1")]),a._v(" "),v("li",[a._v("ack=0")]),a._v(" "),v("li",[a._v("brocker如何保证数据不丢失")]),a._v(" "),v("li",[a._v("ack=all")]),a._v(" "),v("li",[a._v("Consumer如何保证数据不丢失")]),a._v(" "),v("li",[a._v("关闭自动提交offset")])])]),a._v(" "),v("h3",{attrs:{id:"kafka-的数据是放在磁盘上还是内存上-为什么速度会快"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka-的数据是放在磁盘上还是内存上-为什么速度会快"}},[a._v("#")]),a._v(" kafka 的数据是放在磁盘上还是内存上，为什么速度会快")]),a._v(" "),v("ul",[v("li",[v("strong",[a._v("磁盘")]),a._v(" "),v("ul",[v("li",[a._v("顺序读写")]),a._v(" "),v("li",[a._v("内存映射文件")]),a._v(" "),v("li",[a._v("kafka高效文件存储设计")])])])]),a._v(" "),v("h3",{attrs:{id:"kafka中消息的重复消费问题如何解决的✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka中消息的重复消费问题如何解决的✔"}},[a._v("#")]),a._v(" Kafka中消息的重复消费问题如何解决的✔")]),a._v(" "),v("p",[a._v("kafka消费消息都是按照offset进行标记消费的，消费者默认是自动按期提交已经消费的偏移量，默认是每隔5s提交一次，如果出现重平衡的情况，可能会重复消费或丢失数据。"),v("strong",[a._v("我们一般都会禁用掉自动提交偏移量，改为手动提交，当消费成功以后再报告给broker消费的位置")]),a._v("，这样就可以避免消息丢失和重复消费了")]),a._v(" "),v("p",[a._v("为了消息的幂等，我们也可以设置唯一主键来进行区分，或者是加锁，数据库的锁，或者是redis分布式锁，都能解决幂等的问题")]),a._v(" "),v("h3",{attrs:{id:"kafka是如何保证消费的顺序性✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka是如何保证消费的顺序性✔"}},[a._v("#")]),a._v(" Kafka是如何保证消费的顺序性✔")]),a._v(" "),v("p",[a._v("kafka默认存储和消费消息，是不能保证顺序性的，因为一个topic数据可能存储在不同的分区中，每个分区都有一个按照顺序的存储的偏移量，如果消费者关联了多个分区不能保证顺序性")]),a._v(" "),v("p",[a._v("如果有这样的需求的话，我们是可以解决的，"),v("strong",[a._v("把消息都存储同一个分区下就行了")]),a._v("，"),v("strong",[a._v("有两种方式都可以进行设置，第一个是发送消息时指定分区号，第二个是发送消息时按照相同的业务设置相同的key")]),a._v("，因为默认情况下分区也是通过key的hashcode值来选择分区的，hash值如果一样的话，分区肯定也是一样的")]),a._v(" "),v("p",[a._v("Partition中的消息在写入时都是有序的")]),a._v(" "),v("h3",{attrs:{id:"kafka的高可用机制有了解过嘛✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka的高可用机制有了解过嘛✔"}},[a._v("#")]),a._v(" Kafka的高可用机制有了解过嘛✔")]),a._v(" "),v("p",[a._v("主要是有两个层面，第一个是集群，第二个是提供了复制机制")]),a._v(" "),v("ul",[v("li",[v("p",[a._v("kafka集群指的是由多个broker实例组成，即使某一台宕机，也不耽误其他 broker继续对外提供服务")])]),a._v(" "),v("li",[v("p",[a._v("复制机制是可以保证kafka的高可用的，一个topic有多个分区，每个分区有多个副本，有一个leader，其余的是follower，副本存储在不同的broker中； 所有的分区副本的内容是都是相同的，如果leader发生故障时，会自动将其中一个follower提升为leader，保证了系统的容错性、高可用性")])])]),a._v(" "),v("h3",{attrs:{id:"解释一下复制机制中的isr✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#解释一下复制机制中的isr✔"}},[a._v("#")]),a._v(" 解释一下复制机制中的ISR✔")]),a._v(" "),v("p",[a._v("ISR的意思是in-sync replica，就是需要同步复制保存的follower 其中分区副本有很多的follower，分为了两类，一个是ISR，与leader副本同步保存数据，另外一个普通的副本，是异步同步数据，当leader挂掉之后， 会优先从ISR副本列表中选取一个作为leader，因为ISR是同步保存数据，数据更加的完整一些，所以优先选择ISR副本列表")]),a._v(" "),v("h3",{attrs:{id:"kafka数据清理机制了解过嘛✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka数据清理机制了解过嘛✔"}},[a._v("#")]),a._v(" Kafka数据清理机制了解过嘛✔")]),a._v(" "),v("p",[a._v("Kafka中topic的数据存储在分区上，分区如果文件过大会分段存储segment")]),a._v(" "),v("p",[a._v("每个分段都在磁盘上以索引(xxxx.index)和日志文件(xxxx.log)的形式存储， 这样分段的好处是，第一能够减少单个文件内容的大小，查找数据方便，第二方便kafka进行日志清理。")]),a._v(" "),v("p",[a._v("在kafka中提供了两个日志的清理策略：")]),a._v(" "),v("p",[a._v("第一，根据消息的保留时间，当消息保存的时间超过了指定的时间，就会触发清理，默认是168小时（ 7天）")]),a._v(" "),v("p",[a._v("第二是根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阈值，则开始删除最久的消息。这个默认是关闭的")]),a._v(" "),v("p",[a._v("这两个策略都可以通过kafka的broker中的配置文件进行设置")]),a._v(" "),v("h3",{attrs:{id:"kafka中实现高性能的设计有了解过嘛✔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka中实现高性能的设计有了解过嘛✔"}},[a._v("#")]),a._v(" Kafka中实现高性能的设计有了解过嘛✔")]),a._v(" "),v("p",[a._v("Kafka 高性能，是多方面协同的结果，包括宏观架构、分布式存储、ISR 数据 同步、以及高效的利用磁盘、操作系统特性等。主要体现有这么几点：")]),a._v(" "),v("p",[a._v("消息分区：不受单台服务器的限制，可以不受限的处理更多的数据")]),a._v(" "),v("p",[a._v("顺序读写：磁盘顺序读写，提升读写效率")]),a._v(" "),v("p",[a._v("页缓存：把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问")]),a._v(" "),v("p",[a._v("零拷贝：减少上下文切换及数据拷贝")]),a._v(" "),v("p",[a._v("消息压缩：减少磁盘IO和网络IO")]),a._v(" "),v("p",[a._v("分批发送：将消息打包批量发送，减少网络开销")]),a._v(" "),v("h3",{attrs:{id:"kafka的优化"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka的优化"}},[a._v("#")]),a._v(" Kafka的优化")]),a._v(" "),v("ol",[v("li",[v("p",[a._v("资源")])]),a._v(" "),v("li",[v("ol",[v("li",[a._v("内存：1G -> 10G")]),a._v(" "),v("li",[a._v("CPU：8 1 2 -> 12 4 8")]),a._v(" "),v("li",[a._v("磁盘：够")]),a._v(" "),v("li",[a._v("网卡：千兆")])])]),a._v(" "),v("li",[v("p",[a._v("配置")])]),a._v(" "),v("li",[v("ol",[v("li",[a._v("副本：1 -> 2")]),a._v(" "),v("li",[a._v("保存时间：7天 -> 3天")])])]),a._v(" "),v("li",[v("p",[a._v("提高吞吐")])]),a._v(" "),v("li",[v("ol",[v("li",[a._v("生成者：")])])]),a._v(" "),v("li",[v("ol",[v("li",[v("ol",[v("li",[a._v("buffer.size 默认32M -> 64M")]),a._v(" "),v("li",[a._v("batch.size 默认16k -> 32k")]),a._v(" "),v("li",[a._v("linger.ms 默认0ms -> 100ms以内")]),a._v(" "),v("li",[a._v("压缩 默认 none -> LZ4")])])])])]),a._v(" "),v("li",[v("ol",{attrs:{start:"2"}},[v("li",[a._v("消费者")])])]),a._v(" "),v("li",[v("ol",[v("li",[v("ol",[v("li",[a._v("批次大小：50M")]),a._v(" "),v("li",[a._v("批次条数：500条 -> 3000条")])])])])]),a._v(" "),v("li",[v("p",[a._v("保证数据的一致性")])]),a._v(" "),v("li",[v("ol",[v("li",[a._v("丢数：生产者->ack、重试 broker-> 最小同步副本数")]),a._v(" "),v("li",[a._v("重复：开启幂等性")])])])]),a._v(" "),v("h2",{attrs:{id:"rocketmq"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#rocketmq"}},[a._v("#")]),a._v(" RocketMQ")])])}),[],!1,null,null,null);v.default=r.exports}}]);